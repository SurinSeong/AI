{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7a80e2d",
   "metadata": {},
   "source": [
    "### 컴퓨터 비전 : OCR 개발 파이프라인\n",
    "\n",
    "- 이 노트북은 **`OCR` 개발 파이프라인 예제 실습**을 수행하는 노트북입니다.\n",
    "\n",
    "##### TrOCR를 활용한 OCR 개발 파이프라인 예제\n",
    "   1.  사전학습된 TrOCR 모델 Fine-Tuning 및 저장 (Cell 5개)\n",
    "   2.  Fine-tuning 한 모델의 성능 평가 (Cell 9개)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7865fe06",
   "metadata": {},
   "source": [
    "### 01. 사전학습된 TrOCR 모델 Fine-Tuning 및 저장\n",
    "\n",
    "사전학습된 TrOCR 모델(`ddobokki/ko-trocr`)을 AIHub 한국어 OCR 데이터셋으로 Fine-tuning합니다.\n",
    "\n",
    "AIHub 데이터 전처리부터 모델 학습까지 전체 파이프라인을 구현하여 한국어 손글씨 및 인쇄체 텍스트 인식 성능을 향상시킵니다.\n",
    "\n",
    "* AIHub OCR 데이터셋 전처리 클래스로 인쇄체/필기체 JSON 라벨과 이미지를 매칭하여 CSV 형태로 변환\n",
    "* 사전학습된 TrOCR 모델 로드, 한국어 토큰 추가 및 인코더 동결하여 디코더만 학습 설정  \n",
    "* 이미지-텍스트 쌍 데이터를 Hugging Face Dataset 형식으로 변환하고 배치 단위 전처리 수행\n",
    "* Seq2SeqTrainer를 사용하여 모델 Fine-tuning 실행 및 정확도 기반 성능 평가\n",
    "* 학습된 모델과 프로세서를 지정 경로에 저장하고 TensorBoard 로깅으로 학습 과정 모니터링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b51a6c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라이브러리 임포트 완료!\n",
      "PyTorch 버전: 2.7.1+cu128\n",
      "CUDA 사용 가능: True\n"
     ]
    }
   ],
   "source": [
    "# ============================================ \n",
    "# Cell 1: 라이브러리 임포트 \n",
    "# ============================================\n",
    "\n",
    "# 필요한 라이브러리 임포트\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel  # Hugging Face의 TrOCR 모델과 프로세서\n",
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments  # 시퀀스-투-시퀀스 학습을 위한 트레이너\n",
    "from datasets import Dataset, DatasetDict  # Hugging Face datasets 라이브러리\n",
    "import torch  # PyTorch 딥러닝 프레임워크\n",
    "from PIL import Image  # 이미지 처리를 위한 Pillow 라이브러리\n",
    "import numpy as np  # 수치 연산을 위한 NumPy\n",
    "import os  # 운영체제 관련 기능\n",
    "import json  # JSON 파일 처리\n",
    "import pandas as pd  # 데이터프레임 처리\n",
    "from pathlib import Path  # 경로 처리를 위한 pathlib\n",
    "import shutil  # 파일 복사 등 파일 시스템 작업\n",
    "from tqdm import tqdm  # 진행 상황 표시를 위한 프로그레스 바\n",
    "\n",
    "print(\"라이브러리 임포트 완료!\")\n",
    "print(f\"PyTorch 버전: {torch.__version__}\")\n",
    "print(f\"CUDA 사용 가능: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a80a75b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIHubOCRPreprocessor 클래스 정의 완료!\n"
     ]
    }
   ],
   "source": [
    "# ============================================ \n",
    "# Cell 2: AIHub 데이터 전처리 클래스 정의 \n",
    "# ============================================\n",
    "\n",
    "class AIHubOCRPreprocessor:\n",
    "    \"\"\"\n",
    "    AIHub OCR 데이터를 TrOCR 학습용으로 변환하는 전처리 클래스\n",
    "    \n",
    "    AIHub에서 제공하는 한국어 OCR 데이터셋은 다음과 같은 구조를 가집니다:\n",
    "    - Training/Validation 폴더로 분리\n",
    "    - 각 폴더 내에 인쇄체와 필기체 데이터 존재\n",
    "    - 라벨 데이터(JSON)와 원천 데이터(이미지)가 별도 폴더에 저장\n",
    "    \n",
    "    이 클래스는 이러한 구조를 파싱하여 TrOCR 학습에 적합한 형태로 변환합니다.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, base_path):\n",
    "        \"\"\"\n",
    "        전처리기 초기화\n",
    "        \n",
    "        Args:\n",
    "            base_path (str): AIHub 데이터셋의 최상위 경로\n",
    "        \"\"\"\n",
    "        self.base_path = Path(base_path)\n",
    "        \n",
    "    def extract_text_from_json(self, json_path):\n",
    "        \"\"\"\n",
    "        JSON 라벨 파일에서 텍스트 정보를 추출하는 메서드\n",
    "        \n",
    "        AIHub JSON 파일은 다양한 형식을 가질 수 있습니다:\n",
    "        1. 글자 타입: 'letter' 필드에 단일 문자 저장\n",
    "        2. 단어 타입: 'word' 필드에 여러 글자의 배열 저장\n",
    "        3. output 필드: 전체 텍스트가 저장된 경우\n",
    "        \n",
    "        Args:\n",
    "            json_path (str or Path): JSON 파일 경로\n",
    "            \n",
    "        Returns:\n",
    "            str or None: 추출된 텍스트 또는 None\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # UTF-8 인코딩으로 JSON 파일 읽기\n",
    "            with open(json_path, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "            \n",
    "            # 'text' 필드가 없으면 None 반환\n",
    "            if 'text' not in data:\n",
    "                return None\n",
    "                \n",
    "            text_data = data['text']\n",
    "            \n",
    "            # 케이스 1: 글자 타입 처리 (letter 필드)\n",
    "            if 'letter' in text_data:\n",
    "                letter_data = text_data['letter']\n",
    "                \n",
    "                # letter가 딕셔너리인 경우\n",
    "                if isinstance(letter_data, dict):\n",
    "                    # value 키가 있으면 해당 값 반환\n",
    "                    if 'value' in letter_data:\n",
    "                        return str(letter_data['value'])\n",
    "                    # value가 없으면 output 필드 확인\n",
    "                    elif 'output' in text_data:\n",
    "                        return str(text_data['output'])\n",
    "                        \n",
    "                # letter가 직접 문자열인 경우\n",
    "                elif isinstance(letter_data, str):\n",
    "                    return letter_data\n",
    "            \n",
    "            # 케이스 2: 단어 타입 처리 (word 필드)\n",
    "            elif 'word' in text_data:\n",
    "                words = []\n",
    "                # word 배열의 각 요소에서 value 추출\n",
    "                for word_info in text_data['word']:\n",
    "                    if 'value' in word_info:\n",
    "                        words.append(word_info['value'])\n",
    "                # 모든 단어를 공백으로 연결하여 반환\n",
    "                return ' '.join(words)\n",
    "            \n",
    "            # 케이스 3: output 필드가 직접 있는 경우 (폴백 옵션)\n",
    "            elif 'output' in text_data:\n",
    "                return str(text_data['output'])\n",
    "            \n",
    "            # 어떤 케이스에도 해당하지 않으면 None 반환\n",
    "            return None\n",
    "            \n",
    "        except Exception as e:\n",
    "            # 에러 발생 시 경로와 에러 메시지 출력\n",
    "            print(f\"Error processing {json_path}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def create_dataset(self, split='Training', output_dir='trocr_dataset'):\n",
    "        \"\"\"\n",
    "        전체 데이터셋을 생성하는 메인 메서드\n",
    "        \n",
    "        이 메서드는 다음 작업을 수행합니다:\n",
    "        1. 인쇄체와 필기체 데이터를 각각 처리\n",
    "        2. JSON 라벨과 이미지 파일을 매칭\n",
    "        3. 텍스트 추출 및 이미지 복사\n",
    "        4. CSV 파일로 메타데이터 저장\n",
    "        \n",
    "        Args:\n",
    "            split (str): 'Training' 또는 'Validation'\n",
    "            output_dir (str): 출력 디렉토리 경로\n",
    "            \n",
    "        Returns:\n",
    "            pandas.DataFrame: 생성된 데이터셋의 메타데이터\n",
    "        \"\"\"\n",
    "        # 출력 디렉토리 생성\n",
    "        output_path = Path(output_dir)\n",
    "        output_path.mkdir(exist_ok=True)\n",
    "        \n",
    "        # 이미지 저장 폴더 생성 (images/training 또는 images/validation)\n",
    "        images_dir = output_path / 'images' / split.lower()\n",
    "        images_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # 데이터 수집을 위한 리스트 초기화\n",
    "        data_list = []\n",
    "        \n",
    "        # ===== 인쇄체 데이터 처리 =====\n",
    "        print(f\"\\n{split} 인쇄체 처리 중...\")\n",
    "        \n",
    "        # 인쇄체 라벨과 원천 데이터 경로 설정\n",
    "        printed_label_dir = self.base_path / split / f\"[라벨]{split}_인쇄체\" / \"form\"\n",
    "        printed_source_dir = self.base_path / split / f\"[원천]{split}_인쇄체\" / \"form\"\n",
    "        \n",
    "        if printed_label_dir.exists():\n",
    "            # 모든 하위 폴더 (001, 002, ...) 순회\n",
    "            for folder in sorted(printed_label_dir.iterdir()):\n",
    "                if folder.is_dir():\n",
    "                    print(f\"   폴더 {folder.name} 처리 중...\")\n",
    "                    # 현재 폴더의 모든 JSON 파일 찾기\n",
    "                    json_files = list(folder.glob('*.json'))\n",
    "                    \n",
    "                    # 각 JSON 파일 처리 (진행 상황 표시)\n",
    "                    for json_file in tqdm(json_files, desc=f\"   {folder.name}\"):\n",
    "                        # 대응하는 원천 이미지 찾기\n",
    "                        img_folder = printed_source_dir / folder.name\n",
    "                        # 먼저 .jpg 확인\n",
    "                        img_path = img_folder / (json_file.stem + '.jpg')\n",
    "                        \n",
    "                        # .jpg가 없으면 .png 확인\n",
    "                        if not img_path.exists():\n",
    "                            img_path = img_folder / (json_file.stem + '.png')\n",
    "                        \n",
    "                        # 이미지가 없으면 건너뛰기\n",
    "                        if not img_path.exists():\n",
    "                            continue\n",
    "                        \n",
    "                        # JSON에서 텍스트 추출\n",
    "                        text = self.extract_text_from_json(json_file)\n",
    "                        # 텍스트가 없거나 빈 문자열이면 건너뛰기\n",
    "                        if not text or (isinstance(text, str) and text.strip() == ''):\n",
    "                            continue\n",
    "                        \n",
    "                        # 이미지를 새 위치로 복사 (체계적인 이름으로)\n",
    "                        new_img_name = f\"printed_{folder.name}_{json_file.stem}.jpg\"\n",
    "                        new_img_path = images_dir / new_img_name\n",
    "                        shutil.copy2(img_path, new_img_path)\n",
    "                        \n",
    "                        # 메타데이터 추가\n",
    "                        data_list.append({\n",
    "                            'image_path': f'images/{split.lower()}/{new_img_name}',\n",
    "                            'text': text,\n",
    "                            'type': 'printed',  # 인쇄체 표시\n",
    "                            'folder': folder.name,\n",
    "                            'original_file': json_file.stem\n",
    "                        })\n",
    "        \n",
    "        # ===== 필기체 데이터 처리 =====\n",
    "        print(f\"\\n{split} 필기체 처리 중...\")\n",
    "        \n",
    "        # 필기체는 '1.글자'와 '2.단어' 두 가지 서브타입으로 구분\n",
    "        for sub_type in ['1.글자', '2.단어']:\n",
    "            # 필기체 라벨과 원천 데이터 경로 설정\n",
    "            handwritten_label_dir = self.base_path / split / f\"[라벨]{split}_필기체\" / sub_type\n",
    "            handwritten_source_dir = self.base_path / split / f\"[원천]{split}_필기체\" / sub_type\n",
    "            \n",
    "            # 디렉토리 존재 확인\n",
    "            if not handwritten_label_dir.exists():\n",
    "                print(f\"   경고: {sub_type} 라벨 폴더가 없습니다: {handwritten_label_dir}\")\n",
    "                continue\n",
    "                \n",
    "            if not handwritten_source_dir.exists():\n",
    "                print(f\"   경고: {sub_type} 원천 폴더가 없습니다: {handwritten_source_dir}\")\n",
    "                continue\n",
    "                \n",
    "            print(f\"   {sub_type} 처리 중...\")\n",
    "            \n",
    "            # 처리 통계를 위한 카운터\n",
    "            sub_type_count = 0  # 성공적으로 처리된 파일 수\n",
    "            failed_count = 0    # 실패한 파일 수\n",
    "            \n",
    "            # 각 하위 폴더 처리\n",
    "            for folder in sorted(handwritten_label_dir.iterdir()):\n",
    "                if folder.is_dir():\n",
    "                    json_files = list(folder.glob('*.json'))\n",
    "                    print(f\"      폴더 {folder.name} 처리 중... ({len(json_files)}개 파일)\")\n",
    "                    \n",
    "                    # JSON 파일이 없는 경우 경고\n",
    "                    if len(json_files) == 0:\n",
    "                        print(f\"         JSON 파일이 없습니다!\")\n",
    "                        continue\n",
    "                    \n",
    "                    # 폴더별 처리 통계\n",
    "                    folder_success = 0\n",
    "                    folder_failed = 0\n",
    "                    \n",
    "                    # 각 JSON 파일 처리\n",
    "                    for json_file in tqdm(json_files, desc=f\"      {folder.name}\"):\n",
    "                        # 대응하는 원천 이미지 폴더 확인\n",
    "                        img_folder = handwritten_source_dir / folder.name\n",
    "                        \n",
    "                        if not img_folder.exists():\n",
    "                            folder_failed += 1\n",
    "                            failed_count += 1\n",
    "                            continue\n",
    "                        \n",
    "                        # 이미지 파일 찾기\n",
    "                        img_path = img_folder / (json_file.stem + '.jpg')\n",
    "                        if not img_path.exists():\n",
    "                            img_path = img_folder / (json_file.stem + '.png')\n",
    "                        \n",
    "                        if not img_path.exists():\n",
    "                            folder_failed += 1\n",
    "                            failed_count += 1\n",
    "                            continue\n",
    "                        \n",
    "                        # 텍스트 추출\n",
    "                        text = self.extract_text_from_json(json_file)\n",
    "                        if not text or (isinstance(text, str) and text.strip() == ''):\n",
    "                            folder_failed += 1\n",
    "                            failed_count += 1\n",
    "                            continue\n",
    "                        \n",
    "                        # 이미지 복사 및 메타데이터 저장\n",
    "                        try:\n",
    "                            # 파일명에서 점(.)을 언더스코어로 변경 (파일시스템 호환성)\n",
    "                            sub_type_clean = sub_type.replace('.', '_')\n",
    "                            new_img_name = f\"handwritten_{sub_type_clean}_{folder.name}_{json_file.stem}.jpg\"\n",
    "                            new_img_path = images_dir / new_img_name\n",
    "                            shutil.copy2(img_path, new_img_path)\n",
    "                            \n",
    "                            # 메타데이터 추가\n",
    "                            data_list.append({\n",
    "                                'image_path': f'images/{split.lower()}/{new_img_name}',\n",
    "                                'text': text,\n",
    "                                'type': 'handwritten',  # 필기체 표시\n",
    "                                'sub_type': sub_type,   # 글자/단어 구분\n",
    "                                'folder': folder.name,\n",
    "                                'original_file': json_file.stem\n",
    "                            })\n",
    "                            \n",
    "                            sub_type_count += 1\n",
    "                            folder_success += 1\n",
    "                        except Exception as e:\n",
    "                            print(f\"         처리 실패 {json_file.name}: {e}\")\n",
    "                            folder_failed += 1\n",
    "                            failed_count += 1\n",
    "                    \n",
    "                    # 폴더별 처리 결과 출력\n",
    "                    print(f\"         완료: 성공 {folder_success}개, 실패 {folder_failed}개\")\n",
    "            \n",
    "            # 서브타입별 전체 처리 결과 출력\n",
    "            print(f\"      {sub_type} 전체 처리 완료: {sub_type_count}개 파일 (실패: {failed_count}개)\")\n",
    "        \n",
    "        # ===== CSV 저장 및 통계 출력 =====\n",
    "        # 데이터프레임 생성\n",
    "        df = pd.DataFrame(data_list)\n",
    "        \n",
    "        # CSV 파일로 저장 (UTF-8 인코딩)\n",
    "        csv_path = output_path / f'{split.lower()}.csv'\n",
    "        df.to_csv(csv_path, index=False, encoding='utf-8')\n",
    "        \n",
    "        # 처리 결과 통계 출력\n",
    "        print(f\"\\n{split} 데이터셋 생성 완료!\")\n",
    "        print(f\"   - 총 샘플 수: {len(df)}\")\n",
    "        \n",
    "        # 데이터가 있는 경우에만 상세 통계 출력\n",
    "        if len(df) > 0:\n",
    "            print(f\"   - 인쇄체: {len(df[df['type'] == 'printed'])}\")\n",
    "            print(f\"   - 필기체: {len(df[df['type'] == 'handwritten'])}\")\n",
    "            \n",
    "            # 필기체 세부 통계\n",
    "            if 'handwritten' in df['type'].values:\n",
    "                handwritten_df = df[df['type'] == 'handwritten']\n",
    "                if 'sub_type' in handwritten_df.columns:\n",
    "                    print(f\"     - 글자: {len(handwritten_df[handwritten_df['sub_type'] == '1.글자'])}\")\n",
    "                    print(f\"     - 단어: {len(handwritten_df[handwritten_df['sub_type'] == '2.단어'])}\")\n",
    "        else:\n",
    "            print(\"   경고: 데이터가 없습니다! 경로를 확인해주세요.\")\n",
    "            print(f\"   확인할 경로: {self.base_path}\")\n",
    "        \n",
    "        print(f\"   - CSV 위치: {csv_path}\")\n",
    "        \n",
    "        return df\n",
    "\n",
    "print(\"AIHubOCRPreprocessor 클래스 정의 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fec9ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 전처리 시작...\n",
      "\n",
      "=== Training 데이터셋 전처리 ===\n",
      "\n",
      "Training 인쇄체 처리 중...\n",
      "   폴더 001 처리 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   001: 100%|██████████| 1200/1200 [00:01<00:00, 802.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   폴더 002 처리 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   002: 100%|██████████| 1200/1200 [00:01<00:00, 692.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   폴더 003 처리 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   003: 100%|██████████| 1200/1200 [00:01<00:00, 698.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   폴더 004 처리 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   004: 100%|██████████| 1200/1200 [00:01<00:00, 722.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   폴더 005 처리 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   005: 100%|██████████| 1200/1200 [00:01<00:00, 723.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   폴더 006 처리 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   006: 100%|██████████| 1200/1200 [00:01<00:00, 809.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   폴더 007 처리 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   007: 100%|██████████| 1200/1200 [00:02<00:00, 490.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   폴더 008 처리 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   008: 100%|██████████| 1200/1200 [00:03<00:00, 374.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   폴더 009 처리 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   009: 100%|██████████| 1200/1200 [00:01<00:00, 713.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   폴더 010 처리 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   010: 100%|██████████| 1200/1200 [00:02<00:00, 489.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training 필기체 처리 중...\n",
      "   1.글자 처리 중...\n",
      "      폴더 001 처리 중... (2318개 파일)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      001: 100%|██████████| 2318/2318 [00:02<00:00, 959.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         완료: 성공 2318개, 실패 0개\n",
      "      폴더 002 처리 중... (2326개 파일)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      002: 100%|██████████| 2326/2326 [00:02<00:00, 954.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         완료: 성공 2326개, 실패 0개\n",
      "      폴더 003 처리 중... (2342개 파일)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      003: 100%|██████████| 2342/2342 [00:02<00:00, 953.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         완료: 성공 2342개, 실패 0개\n",
      "      폴더 004 처리 중... (1892개 파일)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      004: 100%|██████████| 1892/1892 [00:01<00:00, 961.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         완료: 성공 1892개, 실패 0개\n",
      "      폴더 005 처리 중... (2311개 파일)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      005: 100%|██████████| 2311/2311 [00:02<00:00, 933.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         완료: 성공 2311개, 실패 0개\n",
      "      폴더 006 처리 중... (2307개 파일)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      006: 100%|██████████| 2307/2307 [00:02<00:00, 954.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         완료: 성공 2307개, 실패 0개\n",
      "      폴더 007 처리 중... (2302개 파일)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      007: 100%|██████████| 2302/2302 [00:02<00:00, 940.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         완료: 성공 2302개, 실패 0개\n",
      "      폴더 008 처리 중... (2342개 파일)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      008: 100%|██████████| 2342/2342 [00:02<00:00, 946.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         완료: 성공 2342개, 실패 0개\n",
      "      폴더 009 처리 중... (2134개 파일)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      009: 100%|██████████| 2134/2134 [00:02<00:00, 951.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         완료: 성공 2134개, 실패 0개\n",
      "      폴더 010 처리 중... (2315개 파일)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      010: 100%|██████████| 2315/2315 [00:02<00:00, 977.96it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         완료: 성공 2315개, 실패 0개\n",
      "      1.글자 전체 처리 완료: 22589개 파일 (실패: 0개)\n",
      "   2.단어 처리 중...\n",
      "      폴더 001 처리 중... (5166개 파일)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      001: 100%|██████████| 5166/5166 [00:05<00:00, 966.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         완료: 성공 5166개, 실패 0개\n",
      "      폴더 002 처리 중... (5188개 파일)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      002: 100%|██████████| 5188/5188 [00:05<00:00, 910.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         완료: 성공 5188개, 실패 0개\n",
      "      폴더 003 처리 중... (5202개 파일)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      003: 100%|██████████| 5202/5202 [00:05<00:00, 932.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         완료: 성공 5202개, 실패 0개\n",
      "      폴더 004 처리 중... (4766개 파일)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      004: 100%|██████████| 4766/4766 [00:05<00:00, 942.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         완료: 성공 4766개, 실패 0개\n",
      "      폴더 005 처리 중... (5060개 파일)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      005: 100%|██████████| 5060/5060 [00:05<00:00, 971.16it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         완료: 성공 5060개, 실패 0개\n",
      "      폴더 006 처리 중... (5147개 파일)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      006: 100%|██████████| 5147/5147 [00:05<00:00, 994.86it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         완료: 성공 5147개, 실패 0개\n",
      "      폴더 007 처리 중... (5021개 파일)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      007: 100%|██████████| 5021/5021 [00:04<00:00, 1008.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         완료: 성공 5021개, 실패 0개\n",
      "      폴더 008 처리 중... (5208개 파일)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      008: 100%|██████████| 5208/5208 [00:05<00:00, 980.29it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         완료: 성공 5208개, 실패 0개\n",
      "      폴더 009 처리 중... (4688개 파일)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      009: 100%|██████████| 4688/4688 [00:04<00:00, 962.98it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         완료: 성공 4688개, 실패 0개\n",
      "      폴더 010 처리 중... (5143개 파일)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      010: 100%|██████████| 5143/5143 [00:05<00:00, 942.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         완료: 성공 5143개, 실패 0개\n",
      "      2.단어 전체 처리 완료: 50589개 파일 (실패: 0개)\n",
      "\n",
      "Training 데이터셋 생성 완료!\n",
      "   - 총 샘플 수: 85178\n",
      "   - 인쇄체: 12000\n",
      "   - 필기체: 73178\n",
      "     - 글자: 22589\n",
      "     - 단어: 50589\n",
      "   - CSV 위치: trocr_dataset\\training.csv\n",
      "\n",
      "=== Validation 데이터셋 전처리 ===\n",
      "\n",
      "Validation 인쇄체 처리 중...\n",
      "   폴더 001 처리 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   001: 100%|██████████| 150/150 [00:00<00:00, 566.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   폴더 002 처리 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   002: 100%|██████████| 150/150 [00:00<00:00, 565.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   폴더 003 처리 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   003: 100%|██████████| 150/150 [00:00<00:00, 607.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   폴더 004 처리 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   004: 100%|██████████| 150/150 [00:00<00:00, 316.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   폴더 005 처리 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   005: 100%|██████████| 150/150 [00:00<00:00, 619.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation 필기체 처리 중...\n",
      "   1.글자 처리 중...\n",
      "      폴더 138 처리 중... (2284개 파일)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      138: 100%|██████████| 2284/2284 [00:02<00:00, 979.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         완료: 성공 2284개, 실패 0개\n",
      "      폴더 139 처리 중... (2321개 파일)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      139: 100%|██████████| 2321/2321 [00:01<00:00, 1401.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         완료: 성공 2321개, 실패 0개\n",
      "      폴더 140 처리 중... (1344개 파일)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      140: 100%|██████████| 1344/1344 [00:00<00:00, 1465.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         완료: 성공 1344개, 실패 0개\n",
      "      폴더 141 처리 중... (2181개 파일)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      141: 100%|██████████| 2181/2181 [00:01<00:00, 1481.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         완료: 성공 2181개, 실패 0개\n",
      "      폴더 142 처리 중... (2332개 파일)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      142: 100%|██████████| 2332/2332 [00:01<00:00, 1474.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         완료: 성공 2332개, 실패 0개\n",
      "      1.글자 전체 처리 완료: 10462개 파일 (실패: 0개)\n",
      "   2.단어 처리 중...\n",
      "      폴더 138 처리 중... (5054개 파일)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      138: 100%|██████████| 5054/5054 [00:03<00:00, 1281.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         완료: 성공 5054개, 실패 0개\n",
      "      폴더 139 처리 중... (4899개 파일)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      139: 100%|██████████| 4899/4899 [00:05<00:00, 973.87it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         완료: 성공 4899개, 실패 0개\n",
      "      폴더 140 처리 중... (4473개 파일)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      140: 100%|██████████| 4473/4473 [00:04<00:00, 966.82it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         완료: 성공 4473개, 실패 0개\n",
      "      폴더 141 처리 중... (4660개 파일)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      141: 100%|██████████| 4660/4660 [00:05<00:00, 929.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         완료: 성공 4660개, 실패 0개\n",
      "      폴더 142 처리 중... (5195개 파일)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      142: 100%|██████████| 5195/5195 [00:03<00:00, 1350.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         완료: 성공 5195개, 실패 0개\n",
      "      2.단어 전체 처리 완료: 24281개 파일 (실패: 0개)\n",
      "\n",
      "Validation 데이터셋 생성 완료!\n",
      "   - 총 샘플 수: 35493\n",
      "   - 인쇄체: 750\n",
      "   - 필기체: 34743\n",
      "     - 글자: 10462\n",
      "     - 단어: 24281\n",
      "   - CSV 위치: trocr_dataset\\validation.csv\n",
      "\n",
      "전처리 완료!\n",
      "생성된 파일:\n",
      "- trocr_dataset/training.csv\n",
      "- trocr_dataset/validation.csv\n",
      "- trocr_dataset/images/training/\n",
      "- trocr_dataset/images/validation/\n"
     ]
    }
   ],
   "source": [
    "# ============================================ \n",
    "# Cell 3: 데이터 전처리 실행 (선택사항)\n",
    "# ============================================\n",
    "\n",
    "# 주의: 이 셀은 AIHub 데이터가 존재하고 전처리를 진행하지 않은 경우에만 실행하세요.\n",
    "# 이미 전처리 데이터로 trorcr_dataset.zip의 압축을 풀어서 활용하셔도 됩니다.\n",
    "# 이미 전처리된 데이터가 있다면 이 셀을 건너뛰고 Cell 5로 진행하세요.\n",
    "\n",
    "# AIHub 데이터 경로 설정 (본인의 경로로 수정)\n",
    "AIHUB_DATA_PATH = r'C:\\Users\\SSAFY\\Downloads\\다양한 형태의 한글 문자 OCR'  # 실제 경로로 변경하세요\n",
    "\n",
    "# 전처리기 초기화\n",
    "print(\"데이터 전처리 시작...\")\n",
    "preprocessor = AIHubOCRPreprocessor(AIHUB_DATA_PATH)\n",
    "\n",
    "# Training 데이터셋 전처리\n",
    "print(\"\\n=== Training 데이터셋 전처리 ===\")\n",
    "train_df = preprocessor.create_dataset(split='Training', output_dir='trocr_dataset')\n",
    "\n",
    "# Validation 데이터셋 전처리\n",
    "print(\"\\n=== Validation 데이터셋 전처리 ===\")\n",
    "val_df = preprocessor.create_dataset(split='Validation', output_dir='trocr_dataset')\n",
    "\n",
    "print(\"\\n전처리 완료!\")\n",
    "print(\"생성된 파일:\")\n",
    "print(\"- trocr_dataset/training.csv\")\n",
    "print(\"- trocr_dataset/validation.csv\")\n",
    "print(\"- trocr_dataset/images/training/\")\n",
    "print(\"- trocr_dataset/images/validation/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd2e4c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KoreanTrOCRTrainer 클래스 정의 완료!\n"
     ]
    }
   ],
   "source": [
    "# ============================================ \n",
    "# Cell 4: KoreanTrOCRTrainer 클래스 정의 \n",
    "# ============================================\n",
    "\n",
    "class KoreanTrOCRTrainer:\n",
    "    \"\"\"\n",
    "    AIHub 데이터로 한국어 TrOCR을 학습하는 트레이너 클래스\n",
    "    \n",
    "    TrOCR은 이미지에서 텍스트를 추출하는 Transformer 기반 모델입니다.\n",
    "    이 클래스는 영어로 사전학습된 TrOCR 모델을 한국어로 Fine-tuning합니다.\n",
    "    \n",
    "    주요 기능:\n",
    "    1. 한국어 토큰 추가\n",
    "    2. 데이터셋 준비 및 전처리\n",
    "    3. 모델 학습\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_name=\"ddobokki/ko-trocr\", freeze_encoder=True):\n",
    "        \"\"\"\n",
    "        트레이너 초기화\n",
    "        \n",
    "        Args:\n",
    "            model_name (str): 사용할 사전학습 모델 이름\n",
    "                - \"ddobokki/ko-trocr\": 한국어 손글씨 특화 모델 (base, 권장)\n",
    "                - \"team-lucid/trocr-small-korean\": 한국어 인쇄체 특화 모델 (small)\n",
    "                - \"microsoft/trocr-base-stage1\": 영어 기본 모델\n",
    "                - \"microsoft/trocr-large-stage1\": 영어 대용량 모델\n",
    "            freeze_encoder (bool): 인코더 동결 여부 (기본값: True)\n",
    "                - True: 인코더 가중치 고정, 디코더만 학습 (권장)\n",
    "                - False: 전체 모델 학습\n",
    "        \"\"\"\n",
    "        print(\"모델 초기화 중...\")\n",
    "        \n",
    "        # GPU 사용 가능 여부 확인 및 디바이스 설정\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        print(f\"   디바이스: {self.device}\")\n",
    "        \n",
    "        # TrOCR 프로세서 로드 (이미지 전처리 + 텍스트 토크나이저)\n",
    "        self.processor = TrOCRProcessor.from_pretrained(model_name)\n",
    "        \n",
    "        # TrOCR 모델 로드 (Vision Encoder + Text Decoder)\n",
    "        self.model = VisionEncoderDecoderModel.from_pretrained(model_name)\n",
    "\n",
    "        if freeze_encoder:\n",
    "            print(\"인코더 레이어를 동결합니다...\")\n",
    "            for param in self.model.encoder.parameters():\n",
    "                param.requires_grad = False\n",
    "            \n",
    "            # 동결된 파라미터 수 확인\n",
    "            trainable_params = sum(p.numel() for p in self.model.parameters() if p.requires_grad)\n",
    "            total_params = sum(p.numel() for p in self.model.parameters())\n",
    "            print(f\"학습 가능한 파라미터: {trainable_params:,} / {total_params:,} ({trainable_params/total_params*100:.1f}%)\")\n",
    "        \n",
    "        # 모델을 지정된 디바이스로 이동\n",
    "        self.model.to(self.device)\n",
    "        \n",
    "    def prepare_dataset(self, train_csv, val_csv, max_samples=None):\n",
    "        \"\"\"\n",
    "        학습용 데이터셋을 준비하는 메서드\n",
    "        \n",
    "        CSV 파일을 읽어서 Hugging Face Dataset 형식으로 변환하고,\n",
    "        이미지와 텍스트를 모델 입력 형식에 맞게 전처리합니다.\n",
    "        \n",
    "        Args:\n",
    "            train_csv (str): 학습 데이터 CSV 경로\n",
    "            val_csv (str): 검증 데이터 CSV 경로\n",
    "            max_samples (int, optional): 사용할 최대 샘플 수 (디버깅용)\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (train_dataset, val_dataset)\n",
    "        \"\"\"\n",
    "        print(\"\\n데이터셋 준비 중...\")\n",
    "        \n",
    "        # CSV 파일 읽기\n",
    "        train_df = pd.read_csv(train_csv)\n",
    "        val_df = pd.read_csv(val_csv)\n",
    "        \n",
    "        # 샘플 수 제한 (선택사항, 빠른 테스트용)\n",
    "        if max_samples:\n",
    "            train_df = train_df.sample(n=min(max_samples, len(train_df)), random_state=42)\n",
    "            val_df = val_df.sample(n=min(max_samples//5, len(val_df)), random_state=42)\n",
    "        \n",
    "        print(f\"   학습 샘플: {len(train_df)}\")\n",
    "        print(f\"   검증 샘플: {len(val_df)}\")\n",
    "        \n",
    "        # Pandas DataFrame을 Hugging Face Dataset으로 변환\n",
    "        train_dataset = Dataset.from_pandas(train_df)\n",
    "        val_dataset = Dataset.from_pandas(val_df)\n",
    "        \n",
    "        def preprocess_function(examples):\n",
    "            \"\"\"\n",
    "            배치 단위로 데이터를 전처리하는 내부 함수\n",
    "            \n",
    "            이미지를 로드하고 크기를 조정한 후,\n",
    "            모델 입력 형식(pixel_values, labels)으로 변환합니다.\n",
    "            \n",
    "            Args:\n",
    "                examples: 배치 데이터 (딕셔너리 형태)\n",
    "                \n",
    "            Returns:\n",
    "                dict: 전처리된 데이터\n",
    "            \"\"\"\n",
    "            images = []\n",
    "            # CSV가 있는 디렉토리를 기준으로 상대 경로 해석\n",
    "            base_dir = os.path.dirname(train_csv)\n",
    "            \n",
    "            # 배치의 각 이미지 로드\n",
    "            for img_path in examples['image_path']:\n",
    "                try:\n",
    "                    # 전체 경로 생성\n",
    "                    full_path = os.path.join(base_dir, img_path)\n",
    "                    # RGB 모드로 이미지 열기\n",
    "                    image = Image.open(full_path).convert(\"RGB\")\n",
    "                    \n",
    "                    # 이미지 크기 조정 (메모리 절약 및 학습 효율성)\n",
    "                    max_size = 384  # TrOCR 기본 입력 크기\n",
    "                    if max(image.size) > max_size:\n",
    "                        # 비율 유지하며 크기 조정\n",
    "                        ratio = max_size / max(image.size)\n",
    "                        new_size = tuple(int(dim * ratio) for dim in image.size)\n",
    "                        image = image.resize(new_size, Image.Resampling.LANCZOS)\n",
    "                    \n",
    "                    images.append(image)\n",
    "                except Exception as e:\n",
    "                    print(f\"이미지 로드 실패: {img_path}, {e}\")\n",
    "                    # 로드 실패 시 빈 이미지로 대체 (학습 안정성)\n",
    "                    images.append(Image.new(\"RGB\", (384, 384), \"white\"))\n",
    "            \n",
    "            # 이미지를 모델 입력 형식으로 변환 (정규화 포함)\n",
    "            pixel_values = self.processor(images, return_tensors=\"pt\").pixel_values\n",
    "            \n",
    "            # 텍스트를 토큰화하여 labels 생성\n",
    "            labels = self.processor.tokenizer(\n",
    "                examples['text'],\n",
    "                padding=\"max_length\",     # 최대 길이까지 패딩\n",
    "                max_length=64,           # 한국어는 보통 짧으므로 64로 설정\n",
    "                truncation=True,         # 긴 텍스트는 자르기\n",
    "                return_tensors=\"pt\"\n",
    "            ).input_ids\n",
    "            \n",
    "            # 중요: 패딩 토큰을 -100으로 변경\n",
    "            # -100은 PyTorch에서 loss 계산 시 무시되는 특수 값\n",
    "            labels[labels == self.processor.tokenizer.pad_token_id] = -100\n",
    "            \n",
    "            # 전처리된 데이터 반환\n",
    "            encoding = {\n",
    "                \"pixel_values\": pixel_values,\n",
    "                \"labels\": labels\n",
    "            }\n",
    "            \n",
    "            return encoding\n",
    "        \n",
    "        # 전처리 함수를 데이터셋에 적용\n",
    "        print(\"   전처리 중...\")\n",
    "        \n",
    "        # 학습 데이터 전처리\n",
    "        train_dataset = train_dataset.map(\n",
    "            preprocess_function,\n",
    "            batched=True,                        # 배치 단위로 처리\n",
    "            batch_size=4,                        # 배치 크기 (메모리에 따라 조정)\n",
    "            remove_columns=train_dataset.column_names,  # 원본 컬럼 제거\n",
    "            writer_batch_size=100,               # 디스크 쓰기 배치 크기\n",
    "            keep_in_memory=False,                # 메모리 대신 디스크 사용\n",
    "            load_from_cache_file=True,           # 캐시 활용\n",
    "            desc=\"Training dataset 전처리\"\n",
    "        )\n",
    "        \n",
    "        # 검증 데이터 전처리\n",
    "        val_dataset = val_dataset.map(\n",
    "            preprocess_function,\n",
    "            batched=True,\n",
    "            batch_size=8,\n",
    "            remove_columns=val_dataset.column_names,\n",
    "            writer_batch_size=100,\n",
    "            keep_in_memory=False,\n",
    "            load_from_cache_file=True,\n",
    "            desc=\"Validation dataset 전처리\"\n",
    "        )\n",
    "        \n",
    "        # PyTorch 텐서 형식으로 설정\n",
    "        train_dataset.set_format(type=\"torch\", columns=[\"pixel_values\", \"labels\"])\n",
    "        val_dataset.set_format(type=\"torch\", columns=[\"pixel_values\", \"labels\"])\n",
    "        \n",
    "        return train_dataset, val_dataset\n",
    "    \n",
    "    def compute_metrics(self, eval_preds):\n",
    "        \"\"\"\n",
    "        평가 메트릭을 계산하는 메서드\n",
    "        \n",
    "        모델의 예측값과 정답을 비교하여 정확도를 계산합니다.\n",
    "        \n",
    "        Args:\n",
    "            eval_preds: (predictions, labels) 튜플\n",
    "            \n",
    "        Returns:\n",
    "            dict: 계산된 메트릭\n",
    "        \"\"\"\n",
    "        preds, labels = eval_preds\n",
    "        \n",
    "        # 예측값이 튜플인 경우 첫 번째 요소 사용\n",
    "        if isinstance(preds, tuple):\n",
    "            preds = preds[0]\n",
    "        \n",
    "        # -100인 토큰(패딩)은 pad_token_id로 변경\n",
    "        preds = np.where(preds != -100, preds, self.processor.tokenizer.pad_token_id)\n",
    "        \n",
    "        # 토큰 ID를 텍스트로 디코딩\n",
    "        decoded_preds = self.processor.tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "        \n",
    "        # 레이블도 동일하게 처리\n",
    "        labels = np.where(labels != -100, labels, self.processor.tokenizer.pad_token_id)\n",
    "        decoded_labels = self.processor.tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "        \n",
    "        # 정확도 계산: 예측과 정답이 완전히 일치하는 샘플의 비율\n",
    "        exact_match = sum([pred.strip() == label.strip() \n",
    "                          for pred, label in zip(decoded_preds, decoded_labels)])\n",
    "        accuracy = exact_match / len(decoded_labels) if len(decoded_labels) > 0 else 0\n",
    "        \n",
    "        return {\"accuracy\": accuracy}\n",
    "    \n",
    "    def train(self, train_dataset, val_dataset, output_dir=\"korean-trocr\", \n",
    "              epochs=10, batch_size=8, learning_rate=5e-5):\n",
    "        \"\"\"\n",
    "        모델 학습을 수행하는 메서드\n",
    "        \n",
    "        Seq2SeqTrainer를 사용하여 모델을 학습하고,\n",
    "        주기적으로 검증 및 체크포인트 저장을 수행합니다.\n",
    "        \n",
    "        Args:\n",
    "            train_dataset: 학습 데이터셋\n",
    "            val_dataset: 검증 데이터셋\n",
    "            output_dir (str): 모델 저장 경로\n",
    "            epochs (int): 학습 에폭 수\n",
    "            batch_size (int): 배치 크기\n",
    "            learning_rate (float): 학습률\n",
    "            \n",
    "        Returns:\n",
    "            Seq2SeqTrainer: 학습된 트레이너 객체\n",
    "        \"\"\"\n",
    "        print(f\"\\n학습 시작!\")\n",
    "        print(f\"   에폭: {epochs}\")\n",
    "        print(f\"   배치 크기: {batch_size}\")\n",
    "        print(f\"   학습률: {learning_rate}\")\n",
    "        \n",
    "        def custom_data_collator(features):\n",
    "            \"\"\"\n",
    "            TrOCR용 커스텀 데이터 콜레이터\n",
    "            \n",
    "            배치의 각 샘플을 하나의 텐서로 결합합니다.\n",
    "            \n",
    "            Args:\n",
    "                features: 배치 샘플 리스트\n",
    "                \n",
    "            Returns:\n",
    "                dict: 결합된 배치 데이터\n",
    "            \"\"\"\n",
    "            batch = {}\n",
    "            \n",
    "            # pixel_values 스태킹\n",
    "            if 'pixel_values' in features[0]:\n",
    "                pixel_values = torch.stack([f['pixel_values'] for f in features])\n",
    "                batch['pixel_values'] = pixel_values\n",
    "            \n",
    "            # labels 스태킹\n",
    "            if 'labels' in features[0]:\n",
    "                labels = torch.stack([f['labels'] for f in features])\n",
    "                batch['labels'] = labels\n",
    "                \n",
    "            return batch\n",
    "        \n",
    "        # 학습 설정 정의\n",
    "        training_args = Seq2SeqTrainingArguments(\n",
    "            output_dir=output_dir,               # 출력 디렉토리\n",
    "            num_train_epochs=epochs,             # 전체 에폭 수\n",
    "            per_device_train_batch_size=batch_size,  # GPU당 학습 배치 크기\n",
    "            per_device_eval_batch_size=batch_size,   # GPU당 평가 배치 크기\n",
    "            warmup_steps=1000,                   # 학습률 웜업 스텝\n",
    "            learning_rate=learning_rate,         # 최대 학습률\n",
    "            logging_steps=100,                   # 로깅 주기\n",
    "            save_steps=1000,                     # 체크포인트 저장 주기\n",
    "            eval_steps=1000,                     # 평가 주기\n",
    "            eval_strategy=\"steps\",               # 평가 전략 (steps 또는 epoch)\n",
    "            save_total_limit=3,                  # 최대 체크포인트 개수\n",
    "            predict_with_generate=True,          # 생성 모드로 예측\n",
    "            fp16=torch.cuda.is_available(),      # GPU 사용 시 16비트 연산\n",
    "            push_to_hub=False,                   # Hugging Face Hub 업로드 여부\n",
    "            report_to=[\"tensorboard\"],           # 로깅 도구\n",
    "            load_best_model_at_end=True,         # 학습 종료 시 최고 모델 로드\n",
    "            metric_for_best_model=\"eval_loss\",   # 최고 모델 선택 기준\n",
    "            greater_is_better=False,             # 낮을수록 좋음 (loss)\n",
    "            generation_max_length=64,            # 생성 최대 길이\n",
    "            generation_num_beams=4,              # 빔 서치 빔 개수\n",
    "        )\n",
    "        \n",
    "        # Seq2SeqTrainer 생성\n",
    "        trainer = Seq2SeqTrainer(\n",
    "            model=self.model,                    # 학습할 모델\n",
    "            args=training_args,                  # 학습 설정\n",
    "            train_dataset=train_dataset,         # 학습 데이터셋\n",
    "            eval_dataset=val_dataset,            # 검증 데이터셋\n",
    "            processing_class=self.processor,     # 전처리기\n",
    "            data_collator=custom_data_collator,  # 데이터 콜레이터\n",
    "            compute_metrics=self.compute_metrics,  # 메트릭 계산 함수\n",
    "        )\n",
    "        \n",
    "        # 학습 실행\n",
    "        trainer.train()\n",
    "        \n",
    "        # 모델과 프로세서 저장\n",
    "        print(f\"\\n모델 저장 중...\")\n",
    "        trainer.save_model()\n",
    "        self.processor.save_pretrained(output_dir)\n",
    "        \n",
    "        print(f\"학습 완료! 모델 저장 위치: {output_dir}\")\n",
    "        \n",
    "        return trainer\n",
    "\n",
    "print(\"KoreanTrOCRTrainer 클래스 정의 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "682c7b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "TrOCR 학습 시작\n",
      "==================================================\n",
      "모델 초기화 중...\n",
      "   디바이스: cuda\n",
      "인코더 레이어를 동결합니다...\n",
      "학습 가능한 파라미터: 127,039,784 / 213,693,224 (59.4%)\n",
      "\n",
      "데이터셋 로드 중...\n",
      "\n",
      "데이터셋 준비 중...\n",
      "   학습 샘플: 500\n",
      "   검증 샘플: 100\n",
      "   전처리 중...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3501be939f694d0eb75db314e8c1ae89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training dataset 전처리:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "677194cf5958472f99931e22369ac638",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation dataset 전처리:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "학습 시작...\n",
      "\n",
      "학습 시작!\n",
      "   에폭: 1\n",
      "   배치 크기: 2\n",
      "   학습률: 1e-06\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 00:18, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "모델 저장 중...\n",
      "학습 완료! 모델 저장 위치: aihub-korean-trocr\n",
      "==================================================\n",
      "학습 완료!\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================ \n",
    "# Cell 5: 모델 학습 실행\n",
    "# ============================================\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"TrOCR 학습 시작\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 트레이너 초기화\n",
    "# 사용 가능한 모델:\n",
    "# - \"ddobokki/ko-trocr\": 한국어 손글씨 특화 (권장)\n",
    "# - \"team-lucid/trocr-small-korean\": 한국어 인쇄체 특화\n",
    "# - \"microsoft/trocr-base-stage1\": 영어 기본 모델\n",
    "trainer = KoreanTrOCRTrainer(\n",
    "    model_name=\"ddobokki/ko-trocr\",  # 사용할 모델\n",
    "    freeze_encoder=True              # 인코더 동결 (권장)\n",
    ")\n",
    "\n",
    "# 데이터셋 준비\n",
    "print(\"\\n데이터셋 로드 중...\")\n",
    "train_dataset, val_dataset = trainer.prepare_dataset(\n",
    "    train_csv='trocr_dataset/training.csv',    # 학습 데이터 CSV\n",
    "    val_csv='trocr_dataset/validation.csv',    # 검증 데이터 CSV\n",
    "    max_samples=500  # 빠른 테스트용 (실제 학습 시에는 None으로 설정)\n",
    ")\n",
    "\n",
    "# 모델 학습\n",
    "print(\"\\n학습 시작...\")\n",
    "trained_model = trainer.train(\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=val_dataset,\n",
    "    output_dir='aihub-korean-trocr',     # 모델 저장 경로\n",
    "    epochs=1,                            # 에폭 수 (실제로는 30+ 권장)\n",
    "    batch_size=2 if torch.cuda.is_available() else 1,  # 배치 크기\n",
    "    learning_rate=1e-6                   # 학습률\n",
    ")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"학습 완료!\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a4e954",
   "metadata": {},
   "source": [
    "### 02. Fine-tuning 한 모델의 성능 평가\n",
    "\n",
    "학습된 TrOCR 모델의 성능을 다각도로 평가하고 오류 패턴을 분석합니다.\n",
    "\n",
    "반복 패턴 방지를 위한 개선된 생성 설정과 상세한 시각화를 통해 모델 성능을 종합적으로 진단합니다.\n",
    "\n",
    "* 학습된 TrOCR 모델 로드 및 이미지 전처리를 통한 품질 개선된 텍스트 예측 수행\n",
    "* Character Error Rate(CER)와 Word Error Rate(WER) 메트릭 계산으로 정확한 성능 측정\n",
    "* 인쇄체/필기체 타입별 성능 분석 및 텍스트 길이별 오류 분포 통계 생성\n",
    "* 반복 패턴 감지 및 최악 오류 케이스 분석을 통한 상세한 오류 패턴 진단"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1da5544d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라이브러리 임포트 완료!\n",
      "PyTorch 버전: 2.7.1+cu128\n",
      "CUDA 사용 가능: True\n"
     ]
    }
   ],
   "source": [
    "# ============================================ \n",
    "# Cell 1: 라이브러리 임포트 및 환경 설정\n",
    "# ============================================\n",
    "\n",
    "# 필수 라이브러리 임포트\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "from PIL import Image, ImageEnhance\n",
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import Levenshtein\n",
    "from collections import defaultdict\n",
    "import evaluate  # Hugging Face evaluate 라이브러리\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"라이브러리 임포트 완료!\")\n",
    "print(f\"PyTorch 버전: {torch.__version__}\")\n",
    "print(f\"CUDA 사용 가능: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5fd6a480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrOCREvaluator 클래스 기본 메서드 정의 완료!\n"
     ]
    }
   ],
   "source": [
    "# ============================================ \n",
    "# Cell 2: TrOCREvaluator 클래스 초기화 및 기본 메서드\n",
    "# ============================================\n",
    "\n",
    "class TrOCREvaluator:\n",
    "    \"\"\"\n",
    "    TrOCR 모델 평가를 위한 클래스\n",
    "    \n",
    "    주요 기능:\n",
    "    - 학습된 모델 로드 및 예측\n",
    "    - Character Error Rate (CER) 및 Word Error Rate (WER) 계산\n",
    "    - 타입별 성능 분석 (인쇄체/필기체)\n",
    "    - 오류 패턴 분석\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_path):\n",
    "        \"\"\"\n",
    "        평가기 초기화\n",
    "        \n",
    "        Args:\n",
    "            model_path (str): 학습된 모델이 저장된 디렉토리 경로\n",
    "        \"\"\"\n",
    "        print(f\"[모델 로딩] {model_path}\")\n",
    "        \n",
    "        # 프로세서와 모델 로드\n",
    "        self.processor = TrOCRProcessor.from_pretrained(model_path)\n",
    "        self.model = VisionEncoderDecoderModel.from_pretrained(model_path)\n",
    "        \n",
    "        # GPU 사용 가능 여부 확인 및 디바이스 설정\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()  # 평가 모드로 전환 (드롭아웃 비활성화 등)\n",
    "        \n",
    "        print(f\"[모델 로드 완료] 디바이스: {self.device}\")\n",
    "        \n",
    "        # CER 메트릭 로드 시도\n",
    "        try:\n",
    "            self.cer_metric = evaluate.load(\"cer\")\n",
    "            print(\"[CER 메트릭 로드 완료]\")\n",
    "        except:\n",
    "            print(\"[경고] CER 메트릭 로드 실패. 수동 계산 모드로 전환\")\n",
    "            self.cer_metric = None\n",
    "    \n",
    "    def preprocess_image(self, image):\n",
    "        \"\"\"\n",
    "        이미지 전처리 (품질 개선)\n",
    "        \n",
    "        손글씨 인식 성능 향상을 위한 전처리 단계\n",
    "        \n",
    "        Args:\n",
    "            image (PIL.Image): 원본 이미지\n",
    "            \n",
    "        Returns:\n",
    "            PIL.Image: 전처리된 이미지\n",
    "        \"\"\"\n",
    "        # 대비 향상 (손글씨가 흐릿한 경우 도움)\n",
    "        enhancer = ImageEnhance.Contrast(image)\n",
    "        image = enhancer.enhance(1.3)\n",
    "        \n",
    "        # 선명도 향상\n",
    "        enhancer = ImageEnhance.Sharpness(image)\n",
    "        image = enhancer.enhance(1.2)\n",
    "        \n",
    "        return image\n",
    "    \n",
    "    def normalize_text(self, text, remove_spaces=True):\n",
    "        \"\"\"\n",
    "        텍스트 정규화 함수\n",
    "        \n",
    "        Args:\n",
    "            text (str): 원본 텍스트\n",
    "            remove_spaces (bool): 공백 제거 여부\n",
    "            \n",
    "        Returns:\n",
    "            str: 정규화된 텍스트\n",
    "        \"\"\"\n",
    "        import unicodedata\n",
    "        \n",
    "        # 기본 정규화\n",
    "        text = str(text).strip()\n",
    "        \n",
    "        # 유니코드 정규화 (NFC)\n",
    "        text = unicodedata.normalize('NFC', text)\n",
    "        \n",
    "        if remove_spaces:\n",
    "            # 한글 음절 사이의 공백 제거\n",
    "            # 예: \"초 저 녁\" -> \"초저녁\"\n",
    "            import re\n",
    "            # 한글 문자 사이의 모든 공백 제거\n",
    "            text = re.sub(r'(?<=[가-힣])\\s+(?=[가-힣])', '', text)\n",
    "            # 여러 공백을 하나로\n",
    "            text = re.sub(r'\\s+', ' ', text)\n",
    "            \n",
    "        # 보이지 않는 문자 제거\n",
    "        text = ''.join(char for char in text if char.isprintable() or char in '\\n\\r\\t')\n",
    "        \n",
    "        return text\n",
    "\n",
    "print(\"TrOCREvaluator 클래스 기본 메서드 정의 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "789e0993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 및 메트릭 계산 메서드 추가 완료!\n"
     ]
    }
   ],
   "source": [
    "# ============================================ \n",
    "# Cell 3: 예측 및 메트릭 계산 메서드 추가\n",
    "# ============================================\n",
    "\n",
    "def predict(self, image_path, apply_preprocessing=True):\n",
    "    \"\"\"\n",
    "    이미지에서 텍스트 예측\n",
    "    \n",
    "    반복 패턴 방지를 위한 개선된 생성 설정 포함\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): 이미지 파일 경로\n",
    "        apply_preprocessing (bool): 이미지 전처리 적용 여부\n",
    "        \n",
    "    Returns:\n",
    "        str: 예측된 텍스트\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 이미지 로드 및 RGB 변환\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        \n",
    "        # 전처리 적용 (선택적)\n",
    "        if apply_preprocessing:\n",
    "            image = self.preprocess_image(image)\n",
    "        \n",
    "        # 모델 입력을 위한 전처리\n",
    "        pixel_values = self.processor(image, return_tensors=\"pt\").pixel_values\n",
    "        pixel_values = pixel_values.to(self.device)\n",
    "        \n",
    "        # 예측 수행 (그래디언트 계산 비활성화로 메모리 절약)\n",
    "        with torch.no_grad():\n",
    "            # 개선된 생성 설정\n",
    "            generated_ids = self.model.generate(\n",
    "                pixel_values,\n",
    "                max_length=64,              # 최대 생성 길이\n",
    "                num_beams=5,                # 빔 서치 크기 (품질 향상)\n",
    "                no_repeat_ngram_size=2,     # 2-gram 반복 방지 (중요!)\n",
    "                length_penalty=1.0,         # 길이 패널티 (1.0 = 중립)\n",
    "                early_stopping=True,        # EOS 토큰 발견 시 조기 종료\n",
    "                temperature=1.0,            # 샘플링 온도 (1.0 = 기본)\n",
    "                do_sample=False,            # 결정적 디코딩 사용\n",
    "                repetition_penalty=1.2      # 반복 패널티 (추가 안전장치)\n",
    "            )\n",
    "        \n",
    "        # 생성된 토큰을 텍스트로 디코딩\n",
    "        generated_text = self.processor.batch_decode(\n",
    "            generated_ids, \n",
    "            skip_special_tokens=True  # [PAD], [EOS] 등 특수 토큰 제거\n",
    "        )[0]\n",
    "        \n",
    "        # 후처리: 불필요한 공백 제거\n",
    "        generated_text = generated_text.strip()\n",
    "        \n",
    "        return generated_text\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"[예측 오류] {image_path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def calculate_cer(self, pred_text, true_text):\n",
    "    \"\"\"\n",
    "    Character Error Rate (CER) 계산\n",
    "    \n",
    "    CER = (삽입 + 삭제 + 치환) / 전체 문자 수\n",
    "    \n",
    "    Args:\n",
    "        pred_text (str): 예측된 텍스트\n",
    "        true_text (str): 정답 텍스트\n",
    "        \n",
    "    Returns:\n",
    "        float: CER 값 (0.0 ~ 1.0+)\n",
    "    \"\"\"\n",
    "    # 빈 텍스트 처리\n",
    "    if len(true_text) == 0:\n",
    "        return 0.0 if len(pred_text) == 0 else 1.0\n",
    "    \n",
    "    # Levenshtein 거리 계산 (편집 거리)\n",
    "    distance = Levenshtein.distance(pred_text, true_text)\n",
    "    \n",
    "    # CER = 편집 거리 / 정답 텍스트 길이\n",
    "    return distance / len(true_text)\n",
    "\n",
    "def calculate_wer(self, pred_text, true_text):\n",
    "    \"\"\"\n",
    "    Word Error Rate (WER) 계산\n",
    "    \n",
    "    단어 단위로 오류율을 계산 (한국어의 경우 공백으로 분리)\n",
    "    \n",
    "    Args:\n",
    "        pred_text (str): 예측된 텍스트\n",
    "        true_text (str): 정답 텍스트\n",
    "        \n",
    "    Returns:\n",
    "        float: WER 값 (0.0 ~ 1.0+)\n",
    "    \"\"\"\n",
    "    # 공백 기준으로 단어 분리\n",
    "    pred_words = pred_text.split()\n",
    "    true_words = true_text.split()\n",
    "    \n",
    "    # 빈 텍스트 처리\n",
    "    if len(true_words) == 0:\n",
    "        return 0.0 if len(pred_words) == 0 else 1.0\n",
    "    \n",
    "    # 단어 시퀀스를 다시 문자열로 변환하여 거리 계산\n",
    "    # (더 정교한 WER은 단어 단위 편집 거리를 계산해야 함)\n",
    "    distance = Levenshtein.distance(' '.join(pred_words), ' '.join(true_words))\n",
    "    return distance / len(' '.join(true_words))\n",
    "\n",
    "# 클래스에 메서드 추가\n",
    "TrOCREvaluator.predict = predict\n",
    "TrOCREvaluator.calculate_cer = calculate_cer\n",
    "TrOCREvaluator.calculate_wer = calculate_wer\n",
    "\n",
    "print(\"예측 및 메트릭 계산 메서드 추가 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "78619d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플 테스트 메서드 추가 완료!\n"
     ]
    }
   ],
   "source": [
    "# ============================================ \n",
    "# Cell 4: 샘플 테스트 메서드 추가\n",
    "# ============================================\n",
    "\n",
    "def test_samples(self, test_csv, num_samples=10, return_df=True, normalize_spaces=True):\n",
    "    \"\"\"\n",
    "    빠른 샘플 테스트 (DataFrame 반환 기능 추가)\n",
    "    \n",
    "    전체 평가 전 모델이 제대로 작동하는지 확인\n",
    "    \n",
    "    Args:\n",
    "        test_csv (str): 테스트 데이터 CSV 파일 경로\n",
    "        num_samples (int): 테스트할 샘플 수\n",
    "        return_df (bool): 결과를 DataFrame으로 반환할지 여부\n",
    "        normalize_spaces (bool): 공백 정규화 적용 여부\n",
    "    \n",
    "    Returns:\n",
    "        dict: 평가 결과 딕셔너리 (return_df=True인 경우 detailed_results 포함)\n",
    "    \"\"\"\n",
    "    print(f\"\\n[샘플 테스트] {num_samples}개 샘플 테스트 시작\")\n",
    "    \n",
    "    # CSV 파일 로드\n",
    "    df = pd.read_csv(test_csv)\n",
    "    \n",
    "    # 랜덤 샘플 선택 (재현 가능하도록 random_state 고정)\n",
    "    samples = df.sample(n=min(num_samples, len(df)), random_state=42)\n",
    "    \n",
    "    # 테이블 헤더 출력\n",
    "    print(f\"\\n{'='*100}\")\n",
    "    print(f\"{'파일명':^30} | {'실제 텍스트':^30} | {'예측 텍스트':^30}\")\n",
    "    print(f\"{'='*100}\")\n",
    "    \n",
    "    # 기본 디렉토리 경로\n",
    "    base_dir = os.path.dirname(test_csv)\n",
    "    \n",
    "    # 결과 저장을 위한 리스트 (DataFrame 반환용)\n",
    "    results_list = []\n",
    "    correct = 0  # 완전히 일치하는 예측 수\n",
    "    \n",
    "    # 각 샘플에 대해 예측 수행\n",
    "    for _, row in samples.iterrows():\n",
    "        # 이미지 경로 구성\n",
    "        img_path = os.path.join(base_dir, row['image_path'])\n",
    "        true_text = str(row['text'])\n",
    "        \n",
    "        # 예측 수행\n",
    "        pred_text = self.predict(img_path)\n",
    "        \n",
    "        # 정규화 적용 (선택적)\n",
    "        if normalize_spaces:\n",
    "            true_text_normalized = self.normalize_text(true_text)\n",
    "            pred_text_normalized = self.normalize_text(pred_text)\n",
    "            is_correct = (pred_text_normalized == true_text_normalized)\n",
    "        else:\n",
    "            is_correct = (pred_text == true_text)\n",
    "        \n",
    "        # 메트릭 계산 (정규화된 텍스트로)\n",
    "        cer = self.calculate_cer(pred_text_normalized if normalize_spaces else pred_text, \n",
    "                               true_text_normalized if normalize_spaces else true_text)\n",
    "        wer = self.calculate_wer(pred_text_normalized if normalize_spaces else pred_text, \n",
    "                               true_text_normalized if normalize_spaces else true_text)\n",
    "        \n",
    "        # 긴 텍스트는 표시용으로 자르기\n",
    "        true_display = true_text[:25] + '...' if len(true_text) > 25 else true_text\n",
    "        pred_display = pred_text[:25] + '...' if len(pred_text) > 25 else pred_text\n",
    "        \n",
    "        # 정확도 체크\n",
    "        if is_correct:\n",
    "            correct += 1\n",
    "            status = \"[O]\"  # 정답\n",
    "        else:\n",
    "            status = \"[X]\"  # 오답\n",
    "            \n",
    "            # 디버깅: 틀린 경우 상세 분석\n",
    "            if true_display == pred_display:  # 보기에는 같은데 틀린 경우\n",
    "                print(f\"\\n[디버깅] 숨겨진 차이 분석:\")\n",
    "                print(f\"  실제 텍스트 길이: {len(true_text)}, 예측 텍스트 길이: {len(pred_text)}\")\n",
    "                print(f\"  실제 텍스트 바이트: {true_text.encode('utf-8')}\")\n",
    "                print(f\"  예측 텍스트 바이트: {pred_text.encode('utf-8')}\")\n",
    "                \n",
    "                # 문자 단위 비교\n",
    "                for i, (t, p) in enumerate(zip(true_text, pred_text)):\n",
    "                    if t != p:\n",
    "                        print(f\"  위치 {i}: 실제='{t}'(U+{ord(t):04X}), 예측='{p}'(U+{ord(p):04X})\")\n",
    "                \n",
    "                # 앞뒤 공백 확인\n",
    "                if true_text != true_text.strip() or pred_text != pred_text.strip():\n",
    "                    print(f\"  공백 문제: 실제='{repr(true_text)}', 예측='{repr(pred_text)}'\")\n",
    "                print()\n",
    "        \n",
    "        # 결과 출력\n",
    "        filename = os.path.basename(img_path)[:25]\n",
    "        print(f\"{status} {filename:^28} | {true_display:^30} | {pred_display:^30}\")\n",
    "        \n",
    "        # DataFrame용 결과 저장\n",
    "        if return_df:\n",
    "            results_list.append({\n",
    "                'file': row.get('original_file', os.path.basename(img_path)),\n",
    "                'type': row['type'],\n",
    "                'true_text': true_text,\n",
    "                'pred_text': pred_text,\n",
    "                'is_correct': is_correct,\n",
    "                'cer': cer,\n",
    "                'wer': wer,\n",
    "                'text_length': len(true_text)\n",
    "            })\n",
    "    \n",
    "    # 샘플 정확도 출력\n",
    "    accuracy = correct / num_samples * 100\n",
    "    print(f\"\\n[샘플 정확도] {correct}/{num_samples} ({accuracy:.1f}%)\")\n",
    "    \n",
    "    # 평균 메트릭 계산\n",
    "    if results_list:\n",
    "        avg_cer = np.mean([r['cer'] for r in results_list])\n",
    "        avg_wer = np.mean([r['wer'] for r in results_list])\n",
    "        print(f\"[평균 CER] {avg_cer:.4f}\")\n",
    "        print(f\"[평균 WER] {avg_wer:.4f}\")\n",
    "    \n",
    "    # 결과 반환\n",
    "    result_dict = {\n",
    "        'sample_accuracy': accuracy / 100,\n",
    "        'sample_correct': correct,\n",
    "        'sample_total': num_samples\n",
    "    }\n",
    "    \n",
    "    if return_df and results_list:\n",
    "        results_df = pd.DataFrame(results_list)\n",
    "        result_dict['detailed_results'] = results_df\n",
    "        result_dict['overall_cer'] = avg_cer\n",
    "        result_dict['overall_wer'] = avg_wer\n",
    "    else:\n",
    "        result_dict['detailed_results'] = None\n",
    "    \n",
    "    return result_dict\n",
    "\n",
    "# 클래스에 메서드 추가\n",
    "TrOCREvaluator.test_samples = test_samples\n",
    "\n",
    "print(\"샘플 테스트 메서드 추가 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a0b9f546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 평가 및 오류 분석 메서드 추가 완료!\n"
     ]
    }
   ],
   "source": [
    "# ============================================ \n",
    "# Cell 5: 전체 평가 및 오류 분석 메서드 추가\n",
    "# ============================================\n",
    "\n",
    "def evaluate_full(self, test_csv, save_results=True, normalize_spaces=True):\n",
    "    \"\"\"\n",
    "    전체 데이터셋 종합 평가\n",
    "    \n",
    "    모든 테스트 데이터에 대해 상세한 평가 수행\n",
    "    \n",
    "    Args:\n",
    "        test_csv (str): 테스트 데이터 CSV 파일 경로\n",
    "        save_results (bool): 상세 결과를 CSV로 저장할지 여부\n",
    "        normalize_spaces (bool): 공백 정규화 적용 여부\n",
    "        \n",
    "    Returns:\n",
    "        dict: 평가 결과 딕셔너리\n",
    "    \"\"\"\n",
    "    print(f\"\\n[전체 평가] 데이터셋 평가 시작...\")\n",
    "    \n",
    "    # 데이터 로드\n",
    "    df = pd.read_csv(test_csv)\n",
    "    base_dir = os.path.dirname(test_csv)\n",
    "    \n",
    "    # 결과 저장을 위한 자료구조\n",
    "    results = defaultdict(list)\n",
    "    predictions = []  # 전체 예측 리스트\n",
    "    references = []   # 전체 정답 리스트\n",
    "    \n",
    "    # 타입별 통계를 위한 자료구조\n",
    "    type_stats = defaultdict(lambda: {\n",
    "        'total': 0,         # 전체 샘플 수\n",
    "        'correct': 0,       # 정확히 맞춘 수\n",
    "        'cer_sum': 0,       # CER 합계 (평균 계산용)\n",
    "        'wer_sum': 0,       # WER 합계 (평균 계산용)\n",
    "        'text_lengths': []  # 텍스트 길이 분포\n",
    "    })\n",
    "    \n",
    "    print(f\"총 {len(df)}개 샘플 평가 중...\")\n",
    "    \n",
    "    # 프로그레스 바와 함께 각 샘플 평가\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"평가 진행\"):\n",
    "        # 이미지 경로와 정답 텍스트\n",
    "        img_path = os.path.join(base_dir, row['image_path'])\n",
    "        true_text = str(row['text'])  # 문자열로 변환 (안전성)\n",
    "        \n",
    "        # 예측 수행\n",
    "        pred_text = self.predict(img_path)\n",
    "        \n",
    "        # 전체 예측/정답 리스트에 추가\n",
    "        predictions.append(pred_text)\n",
    "        references.append(true_text)\n",
    "        \n",
    "        # 정확도 및 오류율 계산\n",
    "        is_correct = (pred_text == true_text)\n",
    "        cer = self.calculate_cer(pred_text, true_text)\n",
    "        wer = self.calculate_wer(pred_text, true_text)\n",
    "        \n",
    "        # 타입별 통계 업데이트\n",
    "        text_type = row['type']  # 'printed' 또는 'handwritten'\n",
    "        type_stats[text_type]['total'] += 1\n",
    "        if is_correct:\n",
    "            type_stats[text_type]['correct'] += 1\n",
    "        type_stats[text_type]['cer_sum'] += cer\n",
    "        type_stats[text_type]['wer_sum'] += wer\n",
    "        type_stats[text_type]['text_lengths'].append(len(true_text))\n",
    "        \n",
    "        # 상세 결과 저장\n",
    "        results['file'].append(row.get('original_file', ''))\n",
    "        results['type'].append(text_type)\n",
    "        results['true_text'].append(true_text)\n",
    "        results['pred_text'].append(pred_text)\n",
    "        results['is_correct'].append(is_correct)\n",
    "        results['cer'].append(cer)\n",
    "        results['wer'].append(wer)\n",
    "        results['text_length'].append(len(true_text))\n",
    "        \n",
    "        # 필기체인 경우 세부 타입(글자/단어)도 저장\n",
    "        if 'sub_type' in row and pd.notna(row['sub_type']):\n",
    "            sub_type = row['sub_type']\n",
    "            combined_type = f\"{text_type}_{sub_type}\"\n",
    "            type_stats[combined_type]['total'] += 1\n",
    "            if is_correct:\n",
    "                type_stats[combined_type]['correct'] += 1\n",
    "            type_stats[combined_type]['cer_sum'] += cer\n",
    "            type_stats[combined_type]['wer_sum'] += wer\n",
    "            type_stats[combined_type]['text_lengths'].append(len(true_text))\n",
    "    \n",
    "    # 전체 CER 계산\n",
    "    if self.cer_metric:\n",
    "        # Hugging Face 메트릭 사용\n",
    "        try:\n",
    "            overall_cer = self.cer_metric.compute(\n",
    "                predictions=predictions,\n",
    "                references=references\n",
    "            )\n",
    "        except:\n",
    "            # 실패 시 수동 계산\n",
    "            overall_cer = sum(results['cer']) / len(results['cer'])\n",
    "    else:\n",
    "        # 수동 계산\n",
    "        overall_cer = sum(results['cer']) / len(results['cer'])\n",
    "    \n",
    "    # 전체 WER 계산\n",
    "    overall_wer = sum(results['wer']) / len(results['wer'])\n",
    "    \n",
    "    # ===== 결과 출력 섹션 =====\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"[평가 결과 요약]\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # 전체 성능 메트릭\n",
    "    overall_accuracy = sum(results['is_correct']) / len(results['is_correct'])\n",
    "    print(f\"\\n[전체 성능]\")\n",
    "    print(f\"   - 정확도: {overall_accuracy:.2%} ({sum(results['is_correct'])}/{len(results['is_correct'])})\")\n",
    "    print(f\"   - CER (Character Error Rate): {overall_cer:.4f}\")\n",
    "    print(f\"   - WER (Word Error Rate): {overall_wer:.4f}\")\n",
    "    print(f\"   - 평균 텍스트 길이: {np.mean(results['text_length']):.1f}자\")\n",
    "    \n",
    "    # 결과를 DataFrame으로 변환\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # CSV 파일로 저장 (선택적)\n",
    "    if save_results:\n",
    "        output_path = f\"evaluation_results_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "        results_df.to_csv(output_path, index=False, encoding='utf-8')\n",
    "        print(f\"\\n[결과 저장] 상세 결과가 저장되었습니다: {output_path}\")\n",
    "    \n",
    "    # ===== 오류 분석 섹션 =====\n",
    "    self._analyze_errors(results_df)\n",
    "    \n",
    "    # 평가 결과 반환\n",
    "    return {\n",
    "        'overall_accuracy': overall_accuracy,\n",
    "        'overall_cer': overall_cer,\n",
    "        'overall_wer': overall_wer,\n",
    "        'type_stats': dict(type_stats),\n",
    "        'detailed_results': results_df\n",
    "    }\n",
    "\n",
    "def _analyze_errors(self, results_df):\n",
    "    \"\"\"\n",
    "    오류 패턴 상세 분석 (내부 메서드)\n",
    "    \n",
    "    Args:\n",
    "        results_df (pd.DataFrame): 평가 결과 DataFrame\n",
    "    \"\"\"\n",
    "    print(f\"\\n[오류 분석]\")\n",
    "    \n",
    "    # 오류만 필터링\n",
    "    errors_df = results_df[~results_df['is_correct']]\n",
    "    \n",
    "    if len(errors_df) == 0:\n",
    "        print(\"   모든 예측이 정확합니다!\")\n",
    "        return\n",
    "    \n",
    "    # 1. CER 기준 최악의 오류 케이스\n",
    "    print(\"   * 최대 오류 케이스 (CER 기준 상위 5개):\")\n",
    "    worst_errors = errors_df.nlargest(min(5, len(errors_df)), 'cer')\n",
    "    \n",
    "    for idx, (_, row) in enumerate(worst_errors.iterrows(), 1):\n",
    "        print(f\"   {idx}. CER: {row['cer']:.4f}\")\n",
    "        # 긴 텍스트는 50자로 제한\n",
    "        true_text = row['true_text'][:50] + '...' if len(row['true_text']) > 50 else row['true_text']\n",
    "        pred_text = row['pred_text'][:50] + '...' if len(row['pred_text']) > 50 else row['pred_text']\n",
    "        print(f\"      실제: '{true_text}'\")\n",
    "        print(f\"      예측: '{pred_text}'\")\n",
    "        print()\n",
    "    \n",
    "    # 2. 텍스트 길이별 오류 분포\n",
    "    print(\"   * 텍스트 길이별 오류 분포:\")\n",
    "    length_bins = [0, 10, 20, 50, 100, float('inf')]\n",
    "    bin_labels = ['0-10자', '10-20자', '20-50자', '50-100자', '100자 이상']\n",
    "    \n",
    "    for i in range(len(length_bins)-1):\n",
    "        # 해당 길이 범위의 오류 필터링\n",
    "        mask = (errors_df['text_length'] >= length_bins[i]) & (errors_df['text_length'] < length_bins[i+1])\n",
    "        count = mask.sum()\n",
    "        \n",
    "        if count > 0:\n",
    "            avg_cer = errors_df[mask]['cer'].mean()\n",
    "            print(f\"      {bin_labels[i]}: {count}개 오류 (평균 CER: {avg_cer:.4f})\")\n",
    "    \n",
    "    # 3. 반복 패턴 감지\n",
    "    print(\"\\n   * 반복 패턴 분석:\")\n",
    "    repetition_count = 0\n",
    "    \n",
    "    for _, row in errors_df.iterrows():\n",
    "        pred_text = row['pred_text']\n",
    "        # 간단한 반복 감지: 2글자 이상이 3번 이상 반복\n",
    "        for i in range(len(pred_text)-1):\n",
    "            if i+6 <= len(pred_text):\n",
    "                pattern = pred_text[i:i+2]\n",
    "                if pred_text[i:i+6] == pattern * 3:\n",
    "                    repetition_count += 1\n",
    "                    break\n",
    "    \n",
    "    if repetition_count > 0:\n",
    "        print(f\"      반복 패턴이 감지된 오류: {repetition_count}개 ({repetition_count/len(errors_df)*100:.1f}%)\")\n",
    "        print(\"      → generate 함수의 no_repeat_ngram_size 파라미터 조정 필요\")\n",
    "    else:\n",
    "        print(\"      반복 패턴이 감지되지 않았습니다.\")\n",
    "\n",
    "# 클래스에 메서드 추가\n",
    "TrOCREvaluator.evaluate_full = evaluate_full\n",
    "TrOCREvaluator._analyze_errors = _analyze_errors\n",
    "\n",
    "print(\"전체 평가 및 오류 분석 메서드 추가 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee4c92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시각화 메서드 추가 완료!\n",
      "TrOCREvaluator 클래스 정의 완료!\n"
     ]
    }
   ],
   "source": [
    "# ============================================ \n",
    "# Cell 6: 시각화 메서드 추가\n",
    "# ============================================\n",
    "\n",
    "def visualize_results(self, results_df, title_prefix=\"TrOCR 모델\"):\n",
    "    \"\"\"\n",
    "    결과를 테이블 형식으로 출력 (matplotlib 대신 print 사용)\n",
    "    \n",
    "    Args:\n",
    "        results_df (pd.DataFrame): 평가 결과 DataFrame\n",
    "        title_prefix (str): 출력 제목 접두사\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"{title_prefix} 평가 결과 (샘플 수: {len(results_df)})\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # 1. 타입별 정확도 테이블\n",
    "    print(\"\\n[1. 타입별 정확도]\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"{'타입':^15} | {'정확도':^10} | {'샘플 수':^10}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    type_acc = results_df.groupby('type')['is_correct'].agg(['mean', 'count'])\n",
    "    for idx, (type_name, row) in enumerate(type_acc.iterrows()):\n",
    "        accuracy = row['mean']\n",
    "        count = row['count']\n",
    "        print(f\"{type_name:^15} | {accuracy:>9.2%} | {count:>10}\")\n",
    "    \n",
    "    overall_acc = results_df['is_correct'].mean()\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"{'전체':^15} | {overall_acc:>9.2%} | {len(results_df):>10}\")\n",
    "    \n",
    "    # 2. CER 분포 통계\n",
    "    print(\"\\n[2. CER 분포 통계]\")\n",
    "    print(\"-\" * 50)\n",
    "    cer_values = results_df['cer']\n",
    "    \n",
    "    # 기본 통계량\n",
    "    print(f\"평균 CER: {cer_values.mean():.4f}\")\n",
    "    print(f\"중앙값 CER: {cer_values.median():.4f}\")\n",
    "    print(f\"표준편차: {cer_values.std():.4f}\")\n",
    "    print(f\"최소값: {cer_values.min():.4f}\")\n",
    "    print(f\"최대값: {cer_values.max():.4f}\")\n",
    "    \n",
    "    # CER 구간별 분포\n",
    "    print(\"\\n[CER 구간별 분포]\")\n",
    "    print(\"-\" * 35)\n",
    "    print(f\"{'CER 구간':^15} | {'샘플 수':^10} | {'비율':^8}\")\n",
    "    print(\"-\" * 35)\n",
    "    \n",
    "    cer_bins = [0, 0.1, 0.3, 0.5, 1.0, float('inf')]\n",
    "    cer_labels = ['0.0-0.1', '0.1-0.3', '0.3-0.5', '0.5-1.0', '1.0+']\n",
    "    \n",
    "    for i in range(len(cer_bins)-1):\n",
    "        mask = (cer_values >= cer_bins[i]) & (cer_values < cer_bins[i+1])\n",
    "        count = mask.sum()\n",
    "        ratio = count / len(cer_values) * 100\n",
    "        print(f\"{cer_labels[i]:^15} | {count:>10} | {ratio:>7.1f}%\")\n",
    "    \n",
    "    # 3. 텍스트 길이별 성능\n",
    "    print(\"\\n[3. 텍스트 길이별 성능]\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"{'길이 구간':^15} | {'평균 CER':^10} | {'샘플 수':^10}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    length_bins = [0, 10, 20, 50, 100, float('inf')]\n",
    "    length_labels = ['0-10자', '10-20자', '20-50자', '50-100자', '100자+']\n",
    "    \n",
    "    for i in range(len(length_bins)-1):\n",
    "        mask = (results_df['text_length'] >= length_bins[i]) & (results_df['text_length'] < length_bins[i+1])\n",
    "        if mask.sum() > 0:\n",
    "            avg_cer = results_df[mask]['cer'].mean()\n",
    "            count = mask.sum()\n",
    "            print(f\"{length_labels[i]:^15} | {avg_cer:>10.4f} | {count:>10}\")\n",
    "    \n",
    "    # 4. 타입별 상세 통계\n",
    "    print(\"\\n[4. 타입별 상세 통계]\")\n",
    "    print(\"-\" * 70)\n",
    "    print(f\"{'타입':^15} | {'평균 CER':^10} | {'평균 WER':^10} | {'정확도':^10} | {'샘플 수':^10}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    type_stats = results_df.groupby('type').agg({\n",
    "        'cer': 'mean',\n",
    "        'wer': 'mean',\n",
    "        'is_correct': 'mean',\n",
    "        'file': 'count'\n",
    "    })\n",
    "    \n",
    "    for type_name, row in type_stats.iterrows():\n",
    "        print(f\"{type_name:^15} | {row['cer']:>10.4f} | {row['wer']:>10.4f} | {row['is_correct']:>9.2%} | {row['file']:>10}\")\n",
    "    \n",
    "    # 전체 통계\n",
    "    print(\"-\" * 70)\n",
    "    overall_cer = results_df['cer'].mean()\n",
    "    overall_wer = results_df['wer'].mean()\n",
    "    overall_acc = results_df['is_correct'].mean()\n",
    "    print(f\"{'전체':^15} | {overall_cer:>10.4f} | {overall_wer:>10.4f} | {overall_acc:>9.2%} | {len(results_df):>10}\")\n",
    "    \n",
    "    # 5. 성능 요약\n",
    "    print(\"\\n[5. 성능 요약]\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"완벽히 맞춘 샘플: {results_df['is_correct'].sum()}개 ({results_df['is_correct'].mean():.2%})\")\n",
    "    print(f\"오류가 있는 샘플: {(~results_df['is_correct']).sum()}개 ({(~results_df['is_correct']).mean():.2%})\")\n",
    "    print(f\"평균 텍스트 길이: {results_df['text_length'].mean():.1f}자\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "# 클래스에 메서드 추가\n",
    "TrOCREvaluator.visualize_results = visualize_results\n",
    "\n",
    "print(\"시각화 메서드 추가 완료!\")\n",
    "print(\"TrOCREvaluator 클래스 정의 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3b15ad70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TrOCR 모델 평가 시작\n",
      "============================================================\n",
      "[모델 로딩] aihub-korean-trocr\n",
      "[모델 로드 완료] 디바이스: cuda\n",
      "[경고] CER 메트릭 로드 실패. 수동 계산 모드로 전환\n",
      "\n",
      "============================================================\n",
      "1. 샘플 테스트\n",
      "============================================================\n",
      "\n",
      "[샘플 테스트] 20개 샘플 테스트 시작\n",
      "\n",
      "====================================================================================================\n",
      "             파일명               |             실제 텍스트             |             예측 텍스트            \n",
      "====================================================================================================\n",
      "[O]  handwritten_1_글자_139_1393   |               객                |              객              \n",
      "[O]  handwritten_2_단어_139_1394   |             초 저 녁              |            초저녁            \n",
      "[O]  handwritten_2_단어_141_1414   |             그 렇 게              |            그렇게            \n",
      "[O]  handwritten_2_단어_140_1404   |              육 체               |             육체             \n",
      "[O]  handwritten_1_글자_139_1393   |               녀                |               녀              \n",
      "[O]  handwritten_2_단어_142_1424   |            특 이 하 다             |           특이하다           \n",
      "[O]  handwritten_2_단어_140_1404   |            나 타 나 다             |            나타나다           \n",
      "[O]  handwritten_2_단어_140_1404   |            국 회 의 원             |           국회의원          \n",
      "[O]  handwritten_2_단어_142_1424   |             가 볍 다              |            가볍다            \n",
      "[X]  handwritten_1_글자_141_1413   |               홋                |              혹              \n",
      "[O]  handwritten_1_글자_142_1423   |               잰                |              잰              \n",
      "[O]  handwritten_2_단어_141_1414   |              삼 국               |             삼국            \n",
      "[O]  handwritten_2_단어_140_1404   |              레 몬               |             레몬             \n",
      "[O]  handwritten_2_단어_142_1424   |              법 적               |             법적            \n",
      "[O]  handwritten_2_단어_139_1394   |              차 다               |              차다             \n",
      "[O]  handwritten_2_단어_141_1414   |            건 강 하 다             |           건강하다          \n",
      "[O]  handwritten_1_글자_140_1403   |               궤                |               궤              \n",
      "[O]  handwritten_1_글자_142_1423   |               샹                |              샹              \n",
      "[O]  handwritten_2_단어_139_1394   |              보 험               |             보험             \n",
      "[O]  handwritten_2_단어_141_1414   |            계 속 되 다             |           계속되다           \n",
      "\n",
      "[샘플 정확도] 19/20 (95.0%)\n",
      "[평균 CER] 0.0500\n",
      "[평균 WER] 0.0500\n",
      "\n",
      "샘플 테스트 완료!\n",
      "- 정확도: 95.00%\n",
      "- 평균 CER: 0.0500\n",
      "- 평균 WER: 0.0500\n"
     ]
    }
   ],
   "source": [
    "# ============================================ \n",
    "# Cell 7: 평가기 초기화 및 샘플 테스트 실행\n",
    "# ============================================\n",
    "\n",
    "# 학습된 모델 경로 설정 (실제 경로로 변경 필요)\n",
    "model_path = 'aihub-korean-trocr'  # 본인의 모델 경로로 변경하세요\n",
    "\n",
    "# 평가기 초기화\n",
    "print(\"=\" * 60)\n",
    "print(\"TrOCR 모델 평가 시작\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "evaluator = TrOCREvaluator(model_path)\n",
    "\n",
    "# 빠른 샘플 테스트 (모델 작동 확인 + DataFrame 반환)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"1. 샘플 테스트\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "sample_results = evaluator.test_samples(\n",
    "    'trocr_dataset/validation.csv',    # 테스트 데이터 경로\n",
    "    num_samples=20,                    # 시각화를 위해 샘플 수를 늘림\n",
    "    return_df=True                     # DataFrame 반환 요청\n",
    ")\n",
    "\n",
    "print(f\"\\n샘플 테스트 완료!\")\n",
    "print(f\"- 정확도: {sample_results['sample_accuracy']:.2%}\")\n",
    "if sample_results['detailed_results'] is not None:\n",
    "    print(f\"- 평균 CER: {sample_results['overall_cer']:.4f}\")\n",
    "    print(f\"- 평균 WER: {sample_results['overall_wer']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "657b8a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[샘플 데이터 분석]\n",
      "\n",
      "================================================================================\n",
      "TrOCR 모델 (샘플 20개) 평가 결과 (샘플 수: 20)\n",
      "================================================================================\n",
      "\n",
      "[1. 타입별 정확도]\n",
      "----------------------------------------\n",
      "      타입        |    정확도     |    샘플 수   \n",
      "----------------------------------------\n",
      "  handwritten   |    95.00% |       20.0\n",
      "----------------------------------------\n",
      "      전체        |    95.00% |         20\n",
      "\n",
      "[2. CER 분포 통계]\n",
      "--------------------------------------------------\n",
      "평균 CER: 0.0500\n",
      "중앙값 CER: 0.0000\n",
      "표준편차: 0.2236\n",
      "최소값: 0.0000\n",
      "최대값: 1.0000\n",
      "\n",
      "[CER 구간별 분포]\n",
      "-----------------------------------\n",
      "    CER 구간      |    샘플 수    |    비율   \n",
      "-----------------------------------\n",
      "    0.0-0.1     |         19 |    95.0%\n",
      "    0.1-0.3     |          0 |     0.0%\n",
      "    0.3-0.5     |          0 |     0.0%\n",
      "    0.5-1.0     |          0 |     0.0%\n",
      "     1.0+       |          1 |     5.0%\n",
      "\n",
      "[3. 텍스트 길이별 성능]\n",
      "--------------------------------------------------\n",
      "     길이 구간      |   평균 CER   |    샘플 수   \n",
      "--------------------------------------------------\n",
      "     0-10자      |     0.0500 |         20\n",
      "\n",
      "[4. 타입별 상세 통계]\n",
      "----------------------------------------------------------------------\n",
      "      타입        |   평균 CER   |   평균 WER   |    정확도     |    샘플 수   \n",
      "----------------------------------------------------------------------\n",
      "  handwritten   |     0.0500 |     0.0500 |    95.00% |       20.0\n",
      "----------------------------------------------------------------------\n",
      "      전체        |     0.0500 |     0.0500 |    95.00% |         20\n",
      "\n",
      "[5. 성능 요약]\n",
      "--------------------------------------------------\n",
      "완벽히 맞춘 샘플: 19개 (95.00%)\n",
      "오류가 있는 샘플: 1개 (5.00%)\n",
      "평균 텍스트 길이: 3.7자\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================ \n",
    "# Cell 8: 샘플 데이터 시각화 (테이블 형식)\n",
    "# ============================================\n",
    "\n",
    "# 샘플 테스트 결과 시각화 (테이블 형식)\n",
    "if sample_results['detailed_results'] is not None:\n",
    "    print(\"\\n[샘플 데이터 분석]\")\n",
    "    evaluator.visualize_results(\n",
    "        sample_results['detailed_results'],\n",
    "        title_prefix=\"TrOCR 모델 (샘플 20개)\"\n",
    "    )\n",
    "else:\n",
    "    print(\"시각화할 데이터가 없습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "791973dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "2. 전체 데이터셋 평가\n",
      "============================================================\n",
      "전체 평가는 시간이 오래 걸립니다.\n",
      "실행하려면 아래 주석을 해제하세요:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================ \n",
    "# Cell 9: 전체 데이터셋 평가 (선택사항)\n",
    "# ============================================\n",
    "\n",
    "# 전체 데이터셋 평가 - 시간이 오래 걸리므로 선택적으로 실행\n",
    "# 주석을 해제하여 실행하세요\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"2. 전체 데이터셋 평가\")\n",
    "print(\"=\"*60)\n",
    "print(\"전체 평가는 시간이 오래 걸립니다.\")\n",
    "print(\"실행하려면 아래 주석을 해제하세요:\")\n",
    "print()\n",
    "\n",
    "# full_results = evaluator.evaluate_full('trocr_dataset/validation.csv')\n",
    "# \n",
    "# # 전체 결과 시각화\n",
    "# if full_results['detailed_results'] is not None:\n",
    "#     evaluator.visualize_results(\n",
    "#         full_results['detailed_results'],\n",
    "#         title_prefix=\"TrOCR 모델 (전체 데이터)\"\n",
    "#     )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "computer_vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
