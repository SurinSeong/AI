{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "465d6c0f-9e71-4652-9694-0e4874122006",
   "metadata": {},
   "source": [
    "# 이미지 처리 인공지능 서비스 개발"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81ad9075-b48c-47ed-a3fd-c22556b32bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b16e3654-5ca5-4602-bc8c-804ba7df1cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching model from: https://huggingface.co/google/vit-base-patch16-224\n",
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages\\huggingface_hub\\utils\\_errors.py\", line 304, in hf_raise_for_status\n",
      "    response.raise_for_status()\n",
      "  File \"C:\\Users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages\\requests\\models.py\", line 1024, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 413 Client Error: Payload Too Large for url: https://api-inference.huggingface.co/models/google/vit-base-patch16-224\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages\\gradio\\queueing.py\", line 541, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"C:\\Users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages\\gradio\\route_utils.py\", line 276, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"C:\\Users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages\\gradio\\blocks.py\", line 1928, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"C:\\Users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages\\gradio\\blocks.py\", line 1514, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"C:\\Users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"C:\\Users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2177, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"C:\\Users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 859, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"C:\\Users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages\\gradio\\utils.py\", line 833, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"C:\\Users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages\\gradio\\external.py\", line 371, in query_huggingface_inference_endpoints\n",
      "    data = fn(*data)  # type: ignore\n",
      "  File \"C:\\Users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages\\huggingface_hub\\inference\\_client.py\", line 1021, in image_classification\n",
      "    response = self.post(data=image, model=model, task=\"image-classification\")\n",
      "  File \"C:\\Users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages\\huggingface_hub\\inference\\_client.py\", line 273, in post\n",
      "    hf_raise_for_status(response)\n",
      "  File \"C:\\Users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages\\huggingface_hub\\utils\\_errors.py\", line 371, in hf_raise_for_status\n",
      "    raise HfHubHTTPError(str(e), response=response) from e\n",
      "huggingface_hub.utils._errors.HfHubHTTPError: 413 Client Error: Payload Too Large for url: https://api-inference.huggingface.co/models/google/vit-base-patch16-224 (Request ID: FWya6pC1qZqC7TiUnZwGR)\n",
      "C:\\Users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages\\huggingface_hub\\inference\\_generated\\types\\base.py:139: FutureWarning: Accessing 'ImageClassificationOutputElement' values through dict is deprecated and will be removed from version '0.25'. Use dataclass attributes instead.\n",
      "  warnings.warn(\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages\\huggingface_hub\\utils\\_errors.py\", line 304, in hf_raise_for_status\n",
      "    response.raise_for_status()\n",
      "  File \"C:\\Users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages\\requests\\models.py\", line 1024, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 429 Client Error: Too Many Requests for url: https://api-inference.huggingface.co/models/google/vit-base-patch16-224\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages\\gradio\\queueing.py\", line 541, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"C:\\Users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages\\gradio\\route_utils.py\", line 276, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"C:\\Users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages\\gradio\\blocks.py\", line 1928, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"C:\\Users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages\\gradio\\blocks.py\", line 1514, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"C:\\Users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"C:\\Users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2177, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"C:\\Users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 859, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"C:\\Users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages\\gradio\\utils.py\", line 833, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"C:\\Users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages\\gradio\\external.py\", line 371, in query_huggingface_inference_endpoints\n",
      "    data = fn(*data)  # type: ignore\n",
      "  File \"C:\\Users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages\\huggingface_hub\\inference\\_client.py\", line 1021, in image_classification\n",
      "    response = self.post(data=image, model=model, task=\"image-classification\")\n",
      "  File \"C:\\Users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages\\huggingface_hub\\inference\\_client.py\", line 273, in post\n",
      "    hf_raise_for_status(response)\n",
      "  File \"C:\\Users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages\\huggingface_hub\\utils\\_errors.py\", line 371, in hf_raise_for_status\n",
      "    raise HfHubHTTPError(str(e), response=response) from e\n",
      "huggingface_hub.utils._errors.HfHubHTTPError: 429 Client Error: Too Many Requests for url: https://api-inference.huggingface.co/models/google/vit-base-patch16-224 (Request ID: K4SwRl_fClg_S7xyBhJSU)\n",
      "\n",
      "Rate limit reached. Please log in or use a HF access token\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages\\huggingface_hub\\utils\\_errors.py\", line 304, in hf_raise_for_status\n",
      "    response.raise_for_status()\n",
      "  File \"C:\\Users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages\\requests\\models.py\", line 1024, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 429 Client Error: Too Many Requests for url: https://api-inference.huggingface.co/models/google/vit-base-patch16-224\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages\\gradio\\queueing.py\", line 541, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"C:\\Users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages\\gradio\\route_utils.py\", line 276, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"C:\\Users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages\\gradio\\blocks.py\", line 1928, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"C:\\Users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages\\gradio\\blocks.py\", line 1514, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"C:\\Users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"C:\\Users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2177, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"C:\\Users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 859, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"C:\\Users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages\\gradio\\utils.py\", line 833, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"C:\\Users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages\\gradio\\external.py\", line 371, in query_huggingface_inference_endpoints\n",
      "    data = fn(*data)  # type: ignore\n",
      "  File \"C:\\Users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages\\huggingface_hub\\inference\\_client.py\", line 1021, in image_classification\n",
      "    response = self.post(data=image, model=model, task=\"image-classification\")\n",
      "  File \"C:\\Users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages\\huggingface_hub\\inference\\_client.py\", line 273, in post\n",
      "    hf_raise_for_status(response)\n",
      "  File \"C:\\Users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages\\huggingface_hub\\utils\\_errors.py\", line 371, in hf_raise_for_status\n",
      "    raise HfHubHTTPError(str(e), response=response) from e\n",
      "huggingface_hub.utils._errors.HfHubHTTPError: 429 Client Error: Too Many Requests for url: https://api-inference.huggingface.co/models/google/vit-base-patch16-224 (Request ID: Zqb6G8HSnodYxyDDTcO0T)\n",
      "\n",
      "Rate limit reached. Please log in or use a HF access token\n"
     ]
    }
   ],
   "source": [
    "gr.load('huggingface/google/vit-base-patch16-224').launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00020ccd-1504-4c46-98cc-476c3c88aa8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f95e963c5d2c4ecbb7db17946998a320",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/69.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\tjdtn\\.cache\\huggingface\\hub\\models--google--vit-base-patch16-224. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e997d41217544c9b86c0a58a78970aa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFViTForImageClassification.\n",
      "\n",
      "All the weights of TFViTForImageClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFViTForImageClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eee8ca819456436698eecf22c3270f2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/160 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"image-classification\", model=\"google/vit-base-patch16-224\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35172651-d8e5-4e74-b786-f5e6f85a44dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "# 이미지 분류 함수 만들기\n",
    "def classify_image(img):\n",
    "    results = pipe(img)\n",
    "    # 분류 결과와 그에 대한 확률 반환\n",
    "    return {result['label'] : result['score'] for result in results}\n",
    "\n",
    "iface = \\\n",
    "gr.Interface(\n",
    "    fn=classify_image,\n",
    "    inputs=gr.Image(type='pil', label='Input Image'),\n",
    "    outputs=gr.Label(num_top_classes=5, label='Classification Results')\n",
    ")\n",
    "\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a5f3c8-00c5-4ab3-8255-772a724e6d1f",
   "metadata": {},
   "source": [
    "# 배경 이미지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1346efe1-f77b-4126-9491-b9d112ac5ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gradio_imageslider\n",
      "  Downloading gradio_imageslider-0.0.20-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: gradio in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from gradio_imageslider) (4.37.2)\n",
      "Requirement already satisfied: pillow in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from gradio_imageslider) (10.4.0)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from gradio->gradio_imageslider) (23.2.1)\n",
      "Requirement already satisfied: altair<6.0,>=4.2.0 in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from gradio->gradio_imageslider) (5.3.0)\n",
      "Requirement already satisfied: fastapi in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from gradio->gradio_imageslider) (0.111.0)\n",
      "Requirement already satisfied: ffmpy in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from gradio->gradio_imageslider) (0.3.2)\n",
      "Requirement already satisfied: gradio-client==1.0.2 in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from gradio->gradio_imageslider) (1.0.2)\n",
      "Requirement already satisfied: httpx>=0.24.1 in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from gradio->gradio_imageslider) (0.27.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.3 in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from gradio->gradio_imageslider) (0.23.4)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from gradio->gradio_imageslider) (6.4.0)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from gradio->gradio_imageslider) (3.1.4)\n",
      "Requirement already satisfied: markupsafe~=2.0 in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from gradio->gradio_imageslider) (2.1.5)\n",
      "Requirement already satisfied: matplotlib~=3.0 in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from gradio->gradio_imageslider) (3.9.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from gradio->gradio_imageslider) (1.26.4)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from gradio->gradio_imageslider) (3.10.6)\n",
      "Requirement already satisfied: packaging in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from gradio->gradio_imageslider) (24.1)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from gradio->gradio_imageslider) (2.2.2)\n",
      "Requirement already satisfied: pydantic>=2.0 in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from gradio->gradio_imageslider) (2.8.0)\n",
      "Requirement already satisfied: pydub in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from gradio->gradio_imageslider) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from gradio->gradio_imageslider) (0.0.9)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from gradio->gradio_imageslider) (6.0.1)\n",
      "Requirement already satisfied: ruff>=0.2.2 in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from gradio->gradio_imageslider) (0.5.0)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from gradio->gradio_imageslider) (2.10.0)\n",
      "Requirement already satisfied: tomlkit==0.12.0 in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from gradio->gradio_imageslider) (0.12.0)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from gradio->gradio_imageslider) (0.12.3)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from gradio->gradio_imageslider) (4.12.2)\n",
      "Requirement already satisfied: urllib3~=2.0 in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from gradio->gradio_imageslider) (2.2.2)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from gradio->gradio_imageslider) (0.30.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from gradio-client==1.0.2->gradio->gradio_imageslider) (2024.6.1)\n",
      "Requirement already satisfied: websockets<12.0,>=10.0 in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from gradio-client==1.0.2->gradio->gradio_imageslider) (11.0.3)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from altair<6.0,>=4.2.0->gradio->gradio_imageslider) (4.22.0)\n",
      "Requirement already satisfied: toolz in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from altair<6.0,>=4.2.0->gradio->gradio_imageslider) (0.12.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from httpx>=0.24.1->gradio->gradio_imageslider) (4.4.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from httpx>=0.24.1->gradio->gradio_imageslider) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from httpx>=0.24.1->gradio->gradio_imageslider) (1.0.5)\n",
      "Requirement already satisfied: idna in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from httpx>=0.24.1->gradio->gradio_imageslider) (3.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from httpx>=0.24.1->gradio->gradio_imageslider) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from httpcore==1.*->httpx>=0.24.1->gradio->gradio_imageslider) (0.14.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from huggingface-hub>=0.19.3->gradio->gradio_imageslider) (3.15.4)\n",
      "Requirement already satisfied: requests in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from huggingface-hub>=0.19.3->gradio->gradio_imageslider) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from huggingface-hub>=0.19.3->gradio->gradio_imageslider) (4.66.4)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from importlib-resources<7.0,>=1.3->gradio->gradio_imageslider) (3.19.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from matplotlib~=3.0->gradio->gradio_imageslider) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from matplotlib~=3.0->gradio->gradio_imageslider) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from matplotlib~=3.0->gradio->gradio_imageslider) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from matplotlib~=3.0->gradio->gradio_imageslider) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from matplotlib~=3.0->gradio->gradio_imageslider) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from matplotlib~=3.0->gradio->gradio_imageslider) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from pandas<3.0,>=1.0->gradio->gradio_imageslider) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from pandas<3.0,>=1.0->gradio->gradio_imageslider) (2024.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from pydantic>=2.0->gradio->gradio_imageslider) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.0 in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from pydantic>=2.0->gradio->gradio_imageslider) (2.20.0)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from typer<1.0,>=0.12->gradio->gradio_imageslider) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from typer<1.0,>=0.12->gradio->gradio_imageslider) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from typer<1.0,>=0.12->gradio->gradio_imageslider) (13.7.1)\n",
      "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from fastapi->gradio->gradio_imageslider) (0.37.2)\n",
      "Requirement already satisfied: fastapi-cli>=0.0.2 in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from fastapi->gradio->gradio_imageslider) (0.0.4)\n",
      "Requirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from fastapi->gradio->gradio_imageslider) (5.10.0)\n",
      "Requirement already satisfied: email_validator>=2.0.0 in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from fastapi->gradio->gradio_imageslider) (2.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio->gradio_imageslider) (0.4.6)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from email_validator>=2.0.0->fastapi->gradio->gradio_imageslider) (2.6.1)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->gradio_imageslider) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->gradio_imageslider) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->gradio_imageslider) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->gradio_imageslider) (0.18.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio->gradio_imageslider) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->gradio_imageslider) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->gradio_imageslider) (2.18.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from anyio->httpx>=0.24.1->gradio->gradio_imageslider) (1.2.1)\n",
      "Requirement already satisfied: httptools>=0.5.0 in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from uvicorn[standard]>=0.12.0->fastapi->gradio->gradio_imageslider) (0.6.1)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from uvicorn[standard]>=0.12.0->fastapi->gradio->gradio_imageslider) (1.0.1)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from uvicorn[standard]>=0.12.0->fastapi->gradio->gradio_imageslider) (0.22.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from requests->huggingface-hub>=0.19.3->gradio->gradio_imageslider) (3.3.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio->gradio_imageslider) (0.1.2)\n",
      "Downloading gradio_imageslider-0.0.20-py3-none-any.whl (101 kB)\n",
      "   ---------------------------------------- 0.0/101.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 101.5/101.5 kB 2.9 MB/s eta 0:00:00\n",
      "Installing collected packages: gradio_imageslider\n",
      "Successfully installed gradio_imageslider-0.0.20\n",
      "Collecting rembg\n",
      "  Downloading rembg-2.0.57-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: jsonschema in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from rembg) (4.22.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from rembg) (1.26.4)\n",
      "Collecting onnxruntime (from rembg)\n",
      "  Downloading onnxruntime-1.18.1-cp39-cp39-win_amd64.whl.metadata (4.5 kB)\n",
      "Collecting opencv-python-headless (from rembg)\n",
      "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: pillow in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from rembg) (10.4.0)\n",
      "Collecting pooch (from rembg)\n",
      "  Downloading pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pymatting (from rembg)\n",
      "  Downloading PyMatting-1.1.12-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting scikit-image (from rembg)\n",
      "  Downloading scikit_image-0.24.0-cp39-cp39-win_amd64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: scipy in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from rembg) (1.13.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from rembg) (4.66.4)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from jsonschema->rembg) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from jsonschema->rembg) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from jsonschema->rembg) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from jsonschema->rembg) (0.18.1)\n",
      "Collecting coloredlogs (from onnxruntime->rembg)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from onnxruntime->rembg) (24.3.25)\n",
      "Requirement already satisfied: packaging in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from onnxruntime->rembg) (24.1)\n",
      "Requirement already satisfied: protobuf in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from onnxruntime->rembg) (4.25.3)\n",
      "Collecting sympy (from onnxruntime->rembg)\n",
      "  Downloading sympy-1.12.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from pooch->rembg) (4.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from pooch->rembg) (2.32.3)\n",
      "Collecting numba!=0.49.0 (from pymatting->rembg)\n",
      "  Downloading numba-0.60.0-cp39-cp39-win_amd64.whl.metadata (2.8 kB)\n",
      "Collecting networkx>=2.8 (from scikit-image->rembg)\n",
      "  Downloading networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting imageio>=2.33 (from scikit-image->rembg)\n",
      "  Downloading imageio-2.34.2-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting tifffile>=2022.8.12 (from scikit-image->rembg)\n",
      "  Downloading tifffile-2024.7.2-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting lazy-loader>=0.4 (from scikit-image->rembg)\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from tqdm->rembg) (0.4.6)\n",
      "Collecting llvmlite<0.44,>=0.43.0dev0 (from numba!=0.49.0->pymatting->rembg)\n",
      "  Downloading llvmlite-0.43.0-cp39-cp39-win_amd64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from requests>=2.19.0->pooch->rembg) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from requests>=2.19.0->pooch->rembg) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from requests>=2.19.0->pooch->rembg) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tjdtn\\anaconda3\\envs\\ml-practice\\lib\\site-packages (from requests>=2.19.0->pooch->rembg) (2024.6.2)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime->rembg)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting mpmath<1.4.0,>=1.1.0 (from sympy->onnxruntime->rembg)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting pyreadline3 (from humanfriendly>=9.1->coloredlogs->onnxruntime->rembg)\n",
      "  Downloading pyreadline3-3.4.1-py3-none-any.whl.metadata (2.0 kB)\n",
      "Downloading rembg-2.0.57-py3-none-any.whl (33 kB)\n",
      "Downloading onnxruntime-1.18.1-cp39-cp39-win_amd64.whl (5.6 MB)\n",
      "   ---------------------------------------- 0.0/5.6 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.8/5.6 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 2.2/5.6 MB 23.5 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 4.0/5.6 MB 25.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 5.3/5.6 MB 26.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.6/5.6 MB 22.3 MB/s eta 0:00:00\n",
      "Downloading opencv_python_headless-4.10.0.84-cp37-abi3-win_amd64.whl (38.8 MB)\n",
      "   ---------------------------------------- 0.0/38.8 MB ? eta -:--:--\n",
      "   - -------------------------------------- 1.2/38.8 MB 38.4 MB/s eta 0:00:01\n",
      "   -- ------------------------------------- 2.3/38.8 MB 29.8 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 3.8/38.8 MB 26.7 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 4.6/38.8 MB 24.3 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 5.8/38.8 MB 24.5 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 6.8/38.8 MB 24.1 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 8.1/38.8 MB 23.5 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 9.1/38.8 MB 23.3 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 10.3/38.8 MB 24.2 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 11.3/38.8 MB 22.6 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 12.9/38.8 MB 23.4 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 14.0/38.8 MB 21.8 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 15.3/38.8 MB 23.4 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 16.8/38.8 MB 24.3 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 17.8/38.8 MB 24.2 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 19.1/38.8 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 20.8/38.8 MB 23.4 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 22.0/38.8 MB 25.2 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 23.3/38.8 MB 25.2 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 24.4/38.8 MB 25.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 25.2/38.8 MB 21.8 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 27.0/38.8 MB 21.8 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 28.0/38.8 MB 21.8 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 29.3/38.8 MB 22.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 30.5/38.8 MB 22.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 31.6/38.8 MB 21.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 33.1/38.8 MB 21.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 35.1/38.8 MB 25.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 35.9/38.8 MB 26.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 36.7/38.8 MB 24.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  37.9/38.8 MB 22.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.7/38.8 MB 22.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.7/38.8 MB 22.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.7/38.8 MB 22.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 38.8/38.8 MB 16.8 MB/s eta 0:00:00\n",
      "Downloading pooch-1.8.2-py3-none-any.whl (64 kB)\n",
      "   ---------------------------------------- 0.0/64.6 kB ? eta -:--:--\n",
      "   -------------------------------------- - 61.4/64.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 64.6/64.6 kB 1.2 MB/s eta 0:00:00\n",
      "Downloading PyMatting-1.1.12-py3-none-any.whl (52 kB)\n",
      "   ---------------------------------------- 0.0/53.0 kB ? eta -:--:--\n",
      "   -------------------------------------- - 51.2/53.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 53.0/53.0 kB 689.5 kB/s eta 0:00:00\n",
      "Downloading scikit_image-0.24.0-cp39-cp39-win_amd64.whl (12.9 MB)\n",
      "   ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 1.0/12.9 MB 33.0 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 1.8/12.9 MB 19.2 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 2.9/12.9 MB 15.3 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 5.3/12.9 MB 22.6 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 6.9/12.9 MB 24.4 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 8.0/12.9 MB 24.3 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 9.1/12.9 MB 24.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 10.3/12.9 MB 24.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 11.5/12.9 MB 25.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.7/12.9 MB 29.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.9/12.9 MB 29.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.9/12.9 MB 25.2 MB/s eta 0:00:00\n",
      "Downloading imageio-2.34.2-py3-none-any.whl (313 kB)\n",
      "   ---------------------------------------- 0.0/313.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 313.5/313.5 kB 9.8 MB/s eta 0:00:00\n",
      "Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ---------------------------- ----------- 1.2/1.6 MB 37.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.6/1.6 MB 21.0 MB/s eta 0:00:00\n",
      "Downloading numba-0.60.0-cp39-cp39-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ----------------- ---------------------- 1.2/2.7 MB 38.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 2.4/2.7 MB 25.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.7/2.7 MB 24.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.7/2.7 MB 17.2 MB/s eta 0:00:00\n",
      "Downloading tifffile-2024.7.2-py3-none-any.whl (225 kB)\n",
      "   ---------------------------------------- 0.0/225.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 225.9/225.9 kB 7.0 MB/s eta 0:00:00\n",
      "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "   ---------------------------------------- 0.0/46.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 46.0/46.0 kB 2.4 MB/s eta 0:00:00\n",
      "Downloading sympy-1.12.1-py3-none-any.whl (5.7 MB)\n",
      "   ---------------------------------------- 0.0/5.7 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.4/5.7 MB 8.9 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 1.9/5.7 MB 13.5 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 3.6/5.7 MB 17.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.7/5.7 MB 24.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.7/5.7 MB 20.4 MB/s eta 0:00:00\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "   ---------------------------------------- 0.0/86.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 86.8/86.8 kB 1.6 MB/s eta 0:00:00\n",
      "Downloading llvmlite-0.43.0-cp39-cp39-win_amd64.whl (28.1 MB)\n",
      "   ---------------------------------------- 0.0/28.1 MB ? eta -:--:--\n",
      "   - -------------------------------------- 1.0/28.1 MB 21.1 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 2.0/28.1 MB 18.3 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 2.9/28.1 MB 18.7 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 3.9/28.1 MB 19.3 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 4.9/28.1 MB 19.7 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 6.1/28.1 MB 20.4 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 7.1/28.1 MB 20.8 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 8.3/28.1 MB 21.1 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 9.4/28.1 MB 21.5 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 10.8/28.1 MB 21.1 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 12.3/28.1 MB 22.6 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 13.8/28.1 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 15.5/28.1 MB 23.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 16.8/28.1 MB 23.4 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 18.1/28.1 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 19.5/28.1 MB 24.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 21.4/28.1 MB 24.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 22.5/28.1 MB 23.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 24.0/28.1 MB 21.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 25.2/28.1 MB 21.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 26.4/28.1 MB 22.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  28.1/28.1 MB 22.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  28.1/28.1 MB 23.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  28.1/28.1 MB 23.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 28.1/28.1 MB 18.7 MB/s eta 0:00:00\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 536.2/536.2 kB 17.0 MB/s eta 0:00:00\n",
      "Downloading pyreadline3-3.4.1-py3-none-any.whl (95 kB)\n",
      "   ---------------------------------------- 0.0/95.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 95.2/95.2 kB 2.7 MB/s eta 0:00:00\n",
      "Installing collected packages: pyreadline3, mpmath, tifffile, sympy, opencv-python-headless, networkx, llvmlite, lazy-loader, imageio, humanfriendly, scikit-image, pooch, numba, coloredlogs, pymatting, onnxruntime, rembg\n",
      "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 imageio-2.34.2 lazy-loader-0.4 llvmlite-0.43.0 mpmath-1.3.0 networkx-3.2.1 numba-0.60.0 onnxruntime-1.18.1 opencv-python-headless-4.10.0.84 pooch-1.8.2 pymatting-1.1.12 pyreadline3-3.4.1 rembg-2.0.57 scikit-image-0.24.0 sympy-1.12.1 tifffile-2024.7.2\n"
     ]
    }
   ],
   "source": [
    "!pip3 install gradio_imageslider\n",
    "!pip3 install rembg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c644efca-127b-4625-bde1-2156c717507e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7863\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data from 'https://github.com/danielgatis/rembg/releases/download/v0.0.0/u2net_human_seg.onnx' to file 'C:\\Users\\tjdtn\\.u2net\\u2net_human_seg.onnx'.\n",
      "100%|#######################################| 176M/176M [00:00<00:00, 58.6GB/s]\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from rembg import remove, new_session\n",
    "\n",
    "# 함수 만들기 (이거는 내가 할 줄 알아야 함!)\n",
    "def remove_background(input_image, model):\n",
    "    session = new_session(model)\n",
    "    output = remove(input_image, session=session)\n",
    "    return output\n",
    "\n",
    "iface = \\\n",
    "gr.Interface(\n",
    "    fn=remove_background,\n",
    "    inputs=[\"image\", gr.Radio([\"u2net\", \"u2netp\", \"u2net_human_seg\", \"u2net_cloth_seg\", \"silueta\", \"isnet-general-use\", \"isnet-anime\"], label=\"Model\")],\n",
    "    outputs=\"image\",\n",
    "    title=\"Image Background Remove\",\n",
    "    description=\"This is a gradio wrapper for the rembg library. It can be used to remove the background from an image. You can choose from different models to get the best results.\"\n",
    ")\n",
    "\n",
    "iface.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0e4f55a83a4a44558cc3e4797ae03b6a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "22bee1a1478e4ee5bbca156ee2060d68": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "24c78276a8b84546bedab25ebf212133": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "326ff67083dc4c46a8246235a2c0022a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "3303db9bb0d6437da4f285b746018124": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "342942f45f8d46b09ebf4634525c3af1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_4b54358e605b48cd812e4dfda564cdfd",
       "style": "IPY_MODEL_24c78276a8b84546bedab25ebf212133",
       "value": " 69.7k/69.7k [00:00&lt;00:00, 1.07MB/s]"
      }
     },
     "499def57ae1b4a30817a582256a3f42d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_b919fbdd36cd4cafbcfbc5aea5471a24",
       "max": 69665,
       "style": "IPY_MODEL_9d420f70922c4462b01eb57a8f4952d9",
       "value": 69665
      }
     },
     "4b54358e605b48cd812e4dfda564cdfd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "5f2a3baa45ca442cae383a3bf87fe4db": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "7393afeb002047d09149c8dc14f25bc1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_3303db9bb0d6437da4f285b746018124",
       "max": 160,
       "style": "IPY_MODEL_f17ce9e2998d47f39aa5839a0f18ce83",
       "value": 160
      }
     },
     "8b73444665f3434094684ad95ec51cae": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_22bee1a1478e4ee5bbca156ee2060d68",
       "style": "IPY_MODEL_cb07820c4e0d41688e15188242e6084a",
       "value": "preprocessor_config.json: 100%"
      }
     },
     "8e4d2458342449a3a0530e3f0bdb4f67": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "98eb582d750d4a7e8ad695e3080e77dc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_c9e470782d4c44e2b7544c87c3a75cff",
       "style": "IPY_MODEL_f49636f4ddd94d13b08f43185df90f75",
       "value": "model.safetensors: 100%"
      }
     },
     "9d2f4575b2bc4b2783d5a776b9d91d5c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "9d420f70922c4462b01eb57a8f4952d9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "a57541a4f519488698e6f706ae981e39": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "af9cadbc3fa142cb83c41718b2195788": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_8e4d2458342449a3a0530e3f0bdb4f67",
       "max": 346293852,
       "style": "IPY_MODEL_a57541a4f519488698e6f706ae981e39",
       "value": 346293852
      }
     },
     "b919fbdd36cd4cafbcfbc5aea5471a24": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "bbfa6c1ac4614e2abac42325d2163545": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "bc923c8d1dff45aea343064ec2bba343": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "bea37ef78fa7404fb9554921c20f8e68": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "c9e470782d4c44e2b7544c87c3a75cff": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "cb07820c4e0d41688e15188242e6084a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "dff6c1d2d02a4182b84099568ef2e636": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e38e3a18e40f49c7ae08553c3099359e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_0e4f55a83a4a44558cc3e4797ae03b6a",
       "style": "IPY_MODEL_bea37ef78fa7404fb9554921c20f8e68",
       "value": " 346M/346M [00:12&lt;00:00, 29.8MB/s]"
      }
     },
     "e8f8e5cfcdfb4322830faf0946bae5a0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_dff6c1d2d02a4182b84099568ef2e636",
       "style": "IPY_MODEL_bbfa6c1ac4614e2abac42325d2163545",
       "value": " 160/160 [00:00&lt;00:00, 6.40kB/s]"
      }
     },
     "e997d41217544c9b86c0a58a78970aa8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_98eb582d750d4a7e8ad695e3080e77dc",
        "IPY_MODEL_af9cadbc3fa142cb83c41718b2195788",
        "IPY_MODEL_e38e3a18e40f49c7ae08553c3099359e"
       ],
       "layout": "IPY_MODEL_9d2f4575b2bc4b2783d5a776b9d91d5c"
      }
     },
     "eee8ca819456436698eecf22c3270f2e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_8b73444665f3434094684ad95ec51cae",
        "IPY_MODEL_7393afeb002047d09149c8dc14f25bc1",
        "IPY_MODEL_e8f8e5cfcdfb4322830faf0946bae5a0"
       ],
       "layout": "IPY_MODEL_326ff67083dc4c46a8246235a2c0022a"
      }
     },
     "f1471d7b3be146aea58405bb672b5fda": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f17ce9e2998d47f39aa5839a0f18ce83": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "f49636f4ddd94d13b08f43185df90f75": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f95e963c5d2c4ecbb7db17946998a320": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_fa3e244397d044eea8e6e2a541c6d566",
        "IPY_MODEL_499def57ae1b4a30817a582256a3f42d",
        "IPY_MODEL_342942f45f8d46b09ebf4634525c3af1"
       ],
       "layout": "IPY_MODEL_bc923c8d1dff45aea343064ec2bba343"
      }
     },
     "fa3e244397d044eea8e6e2a541c6d566": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_f1471d7b3be146aea58405bb672b5fda",
       "style": "IPY_MODEL_5f2a3baa45ca442cae383a3bf87fe4db",
       "value": "config.json: 100%"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
