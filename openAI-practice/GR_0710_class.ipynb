{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d40aed6-d2f1-4da2-8915-41093d757cd8",
   "metadata": {},
   "source": [
    "# Korean unsmile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a9e1a80-f74f-443d-879e-80166e8a7200",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import torch\n",
    "import tensorflow\n",
    "from transformers import pipeline, AutoModelForSequenceClassification, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "216ec927-1b3e-4dbb-84c6-89bbf8be1e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1c752e2-25fc-4485-b825-c54406833212",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\n",
    "    \"여성/가족\",\n",
    "    \"남성\",\n",
    "    \"성소수자\",\n",
    "    \"인종/국적\",\n",
    "    \"연령\",\n",
    "    \"지역\",\n",
    "    \"종교\",\n",
    "    \"기타 혐오\",\n",
    "    \"악플/욕설\",\n",
    "    \"clean\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0123e943-8291-456e-86ee-9c12bd52994f",
   "metadata": {},
   "source": [
    "## 모델 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20b4290d-1858-4bee-8110-ec9cddf86d1c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "\nAutoModelForSequenceClassification requires the PyTorch library but it was not found in your environment.\nHowever, we were able to find a TensorFlow installation. TensorFlow classes begin\nwith \"TF\", but are otherwise identically named to our PyTorch classes. This\nmeans that the TF equivalent of the class you tried to import would be \"TFAutoModelForSequenceClassification\".\nIf you want to use TensorFlow, please use TF classes instead!\n\nIf you really do want to use PyTorch please go to\nhttps://pytorch.org/get-started/locally/ and follow the instructions that\nmatch your environment.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForSequenceClassification\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msmilegate-ai/kor_unsmile\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msmilegate-ai/kor_unsmile\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml-practice\\lib\\site-packages\\transformers\\utils\\import_utils.py:1500\u001b[0m, in \u001b[0;36mDummyObject.__getattribute__\u001b[1;34m(cls, key)\u001b[0m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_from_config\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1499\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(key)\n\u001b[1;32m-> 1500\u001b[0m \u001b[43mrequires_backends\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backends\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml-practice\\lib\\site-packages\\transformers\\utils\\import_utils.py:1479\u001b[0m, in \u001b[0;36mrequires_backends\u001b[1;34m(obj, backends)\u001b[0m\n\u001b[0;32m   1477\u001b[0m \u001b[38;5;66;03m# Raise an error for users who might not realize that classes without \"TF\" are torch-only\u001b[39;00m\n\u001b[0;32m   1478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m backends \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m backends \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_available() \u001b[38;5;129;01mand\u001b[39;00m is_tf_available():\n\u001b[1;32m-> 1479\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(PYTORCH_IMPORT_ERROR_WITH_TF\u001b[38;5;241m.\u001b[39mformat(name))\n\u001b[0;32m   1481\u001b[0m \u001b[38;5;66;03m# Raise the inverse error for PyTorch users trying to load TF classes\u001b[39;00m\n\u001b[0;32m   1482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m backends \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m backends \u001b[38;5;129;01mand\u001b[39;00m is_torch_available() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tf_available():\n",
      "\u001b[1;31mImportError\u001b[0m: \nAutoModelForSequenceClassification requires the PyTorch library but it was not found in your environment.\nHowever, we were able to find a TensorFlow installation. TensorFlow classes begin\nwith \"TF\", but are otherwise identically named to our PyTorch classes. This\nmeans that the TF equivalent of the class you tried to import would be \"TFAutoModelForSequenceClassification\".\nIf you want to use TensorFlow, please use TF classes instead!\n\nIf you really do want to use PyTorch please go to\nhttps://pytorch.org/get-started/locally/ and follow the instructions that\nmatch your environment.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"smilegate-ai/kor_unsmile\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"smilegate-ai/kor_unsmile\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0aa6e7-4515-4d93-9e72-6680c3972ab3",
   "metadata": {},
   "source": [
    "## 악플 감지 함수 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c32825c9-40c7-4637-9684-547692a30d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 중요중요 ##\n",
    "def checkHateSpeech(text):\n",
    "    with torch.no_grad(): # model의 gradient 계산 비활성화\n",
    "        inputs = tokenizer(text, return_tensors='pt') # return_tensors : pytorch\n",
    "        # 변환된 입력(inputs) 모델에 넣어 결과를 도출\n",
    "        outputs = model(**inputs)\n",
    "        \n",
    "        logits = outputs['logits'] # logits : 승비\n",
    "\n",
    "        # 원시 예측값을 확률로 변환한다. (sigmoid : 0 ~ 1 사이)\n",
    "        probs = torch.sigmoid(logits)\n",
    "        # 0 ~ 1 사이에 나오는 확률값 >> labels과 매칭 >> dict() 형태로 반환\n",
    "        probs_by_labels = {labels[i] : float(probs[0][i]) for i in range(len(labels))}\n",
    "\n",
    "        return probs_by_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6755fa-e702-40fb-bc1d-c86eaef06d18",
   "metadata": {},
   "source": [
    "## Gradio 화면 그리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe467442-8f35-4fe5-99e3-468a83283c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "iface = \\\n",
    "gr.Interface(\n",
    "    fn=checkHateSpeech,\n",
    "    inputs=gr.Textbox(label='Input Text'),\n",
    "    outputs=gr.Label(label='혐오 발언 분석', num_top_classes=5),\n",
    "    examples=[\n",
    "        '사랑해요. 증오해요.'\n",
    "    ],\n",
    ")\n",
    "\n",
    "iface.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
